{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0uSlnFQn9VDW"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Install system dependencies for OpenGL and EGL\n",
    "!apt-get update\n",
    "!apt-get install -y \\\n",
    "    libegl1-mesa \\\n",
    "    libegl1-mesa-dev \\\n",
    "    libgl1-mesa-dev \\\n",
    "    libgl1-mesa-glx \\\n",
    "    libglew-dev \\\n",
    "    libosmesa6-dev \\\n",
    "    software-properties-common\n",
    "\n",
    "%pip install mujoco\n",
    "%pip install mujoco_mjx\n",
    "%pip install ml_collections\n",
    "%pip install PyOpenGL PyOpenGL_accelerate\n",
    "\n",
    "# Clone and install the repository properly\n",
    "!rm -rf /home/jovyan/mujoco_playground\n",
    "!git clone https://github.com/Itssshikhar/mujoco_playground.git /home/jovyan/mujoco_playground\n",
    "%cd /home/jovyan/mujoco_playground\n",
    "%pip install -e .\n",
    "%cd /home/jovyan\n",
    "\n",
    "# Add the repository root to Python path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('/home/jovyan/mujoco_playground'))\n",
    "os.environ['PYTHONPATH'] = os.path.abspath('/home/jovyan/mujoco_playground') + ':' + os.environ.get('PYTHONPATH', '')\n",
    "\n",
    "# Set environment variable for mujoco_menagerie path\n",
    "os.environ['MUJOCO_MENAGERIE_PATH'] = '/home/jovyan/external_deps/mujoco_menagerie'\n",
    "\n",
    "# Configure rendering backend with fallbacks\n",
    "def try_import_mjx_env():\n",
    "    from mujoco_playground._src import mjx_env\n",
    "    return True\n",
    "    \n",
    "success = False\n",
    "\n",
    "# Try EGL first\n",
    "try:\n",
    "    os.environ['MUJOCO_GL'] = 'egl'\n",
    "    os.environ['PYOPENGL_PLATFORM'] = 'egl'\n",
    "    success = try_import_mjx_env()\n",
    "    print('Successfully initialized with EGL backend')\n",
    "except:\n",
    "    # Try OSMESA second\n",
    "    try:\n",
    "        os.environ['MUJOCO_GL'] = 'osmesa'\n",
    "        os.environ['PYOPENGL_PLATFORM'] = 'osmesa'\n",
    "        success = try_import_mjx_env()\n",
    "        print('Successfully initialized with OSMESA backend')\n",
    "    except:\n",
    "        # Try GLFW last\n",
    "        try:\n",
    "            os.environ['MUJOCO_GL'] = 'glfw'\n",
    "            os.environ['PYOPENGL_PLATFORM'] = 'glfw'\n",
    "            success = try_import_mjx_env()\n",
    "            print('Successfully initialized with GLFW backend')\n",
    "        except:\n",
    "            print('Failed to initialize any rendering backend')\n",
    "\n",
    "# Create a minimal mjx_env.py if all imports fail\n",
    "if not success:\n",
    "    print('Creating minimal mjx_env.py...')\n",
    "    %%writefile /home/jovyan/mujoco_playground/mujoco_playground/_src/mjx_env.py\n",
    "    \"\"\"Minimal MJX environment module.\"\"\"\n",
    "    import jax\n",
    "    import mujoco\n",
    "    from mujoco import mjx\n",
    "    \n",
    "    class MJXEnv:\n",
    "        \"\"\"Base class for MJX environments.\"\"\"\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "# Verify the setup\n",
    "try:\n",
    "    from mujoco_playground._src import mjx_env\n",
    "    print('Final import verification successful!')\n",
    "except ImportError as e:\n",
    "    print(f'Final import verification failed: {str(e)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U7tUgFuaLYtq",
    "outputId": "84dc7c66-d86a-4f7c-c75a-5ca2562c8228",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: playground in /usr/local/lib/python3.10/dist-packages (0.0.3)\n",
      "Requirement already satisfied: brax>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from playground) (0.12.1)\n",
      "Requirement already satisfied: etils in /usr/local/lib/python3.10/dist-packages (from playground) (1.11.0)\n",
      "Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (from playground) (0.10.2)\n",
      "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from playground) (0.5.0)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from playground) (5.3.0)\n",
      "Requirement already satisfied: ml-collections in /usr/local/lib/python3.10/dist-packages (from playground) (1.0.0)\n",
      "Requirement already satisfied: mujoco-mjx>=3.2.7 in /usr/local/lib/python3.10/dist-packages (from playground) (3.2.7)\n",
      "Requirement already satisfied: mujoco>=3.2.7 in /usr/local/lib/python3.10/dist-packages (from playground) (3.2.7)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from playground) (4.67.1)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from brax>=0.12.1->playground) (2.1.0)\n",
      "Requirement already satisfied: dm_env in /usr/local/lib/python3.10/dist-packages (from brax>=0.12.1->playground) (1.6)\n",
      "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from brax>=0.12.1->playground) (3.1.0)\n",
      "Requirement already satisfied: flask_cors in /usr/local/lib/python3.10/dist-packages (from brax>=0.12.1->playground) (5.0.0)\n",
      "Requirement already satisfied: grpcio in /usr/local/lib/python3.10/dist-packages (from brax>=0.12.1->playground) (1.70.0)\n",
      "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (from brax>=0.12.1->playground) (0.26.2)\n",
      "Requirement already satisfied: jaxlib>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from brax>=0.12.1->playground) (0.5.0)\n",
      "Requirement already satisfied: jaxopt in /usr/local/lib/python3.10/dist-packages (from brax>=0.12.1->playground) (0.8.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from brax>=0.12.1->playground) (3.1.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from brax>=0.12.1->playground) (2.2.0)\n",
      "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from brax>=0.12.1->playground) (0.2.4)\n",
      "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from brax>=0.12.1->playground) (0.11.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from brax>=0.12.1->playground) (11.0.0)\n",
      "Requirement already satisfied: pytinyrenderer in /usr/local/lib/python3.10/dist-packages (from brax>=0.12.1->playground) (0.0.14)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from brax>=0.12.1->playground) (1.15.1)\n",
      "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.10/dist-packages (from brax>=0.12.1->playground) (2.6.2.2)\n",
      "Requirement already satisfied: trimesh in /usr/local/lib/python3.10/dist-packages (from brax>=0.12.1->playground) (4.6.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from brax>=0.12.1->playground) (4.12.2)\n",
      "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from jax->playground) (0.5.1)\n",
      "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.10/dist-packages (from jax->playground) (3.4.0)\n",
      "Requirement already satisfied: glfw in /usr/local/lib/python3.10/dist-packages (from mujoco>=3.2.7->playground) (2.8.0)\n",
      "Requirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco>=3.2.7->playground) (3.1.9)\n",
      "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax->playground) (1.1.0)\n",
      "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax->playground) (0.1.71)\n",
      "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax->playground) (13.9.4)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax->playground) (6.0.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from ml-collections->playground) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax->playground) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax->playground) (2.18.0)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from dm_env->brax>=0.12.1->playground) (0.1.8)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=3.2.7->playground) (2024.12.0)\n",
      "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=3.2.7->playground) (6.5.2)\n",
      "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=3.2.7->playground) (3.21.0)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.10/dist-packages (from flask->brax>=0.12.1->playground) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.10/dist-packages (from flask->brax>=0.12.1->playground) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from flask->brax>=0.12.1->playground) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.10/dist-packages (from flask->brax>=0.12.1->playground) (1.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->brax>=0.12.1->playground) (3.0.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym->brax>=0.12.1->playground) (3.1.1)\n",
      "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym->brax>=0.12.1->playground) (0.0.8)\n",
      "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.10/dist-packages (from optax->brax>=0.12.1->playground) (0.1.88)\n",
      "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->brax>=0.12.1->playground) (1.6.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->brax>=0.12.1->playground) (5.29.3)\n",
      "Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->brax>=0.12.1->playground) (4.11.0)\n",
      "Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->brax>=0.12.1->playground) (3.19.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX->brax>=0.12.1->playground) (24.2)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.87->optax->brax>=0.12.1->playground) (1.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax->playground) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: jax[cuda12] in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
      "Requirement already satisfied: jaxlib<=0.5.0,>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12]) (0.5.0)\n",
      "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12]) (0.5.1)\n",
      "Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12]) (2.2.0)\n",
      "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.10/dist-packages (from jax[cuda12]) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12]) (1.15.1)\n",
      "Requirement already satisfied: jax-cuda12-plugin<=0.5.0,>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.0,>=0.5.0; extra == \"cuda12\"->jax[cuda12]) (0.5.0)\n",
      "Requirement already satisfied: jax-cuda12-pjrt==0.5.0 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin<=0.5.0,>=0.5.0->jax-cuda12-plugin[with_cuda]<=0.5.0,>=0.5.0; extra == \"cuda12\"->jax[cuda12]) (0.5.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12>=12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.0,>=0.5.0; extra == \"cuda12\"->jax[cuda12]) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12>=12.1.105 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.0,>=0.5.0; extra == \"cuda12\"->jax[cuda12]) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-nvcc-cu12>=12.6.85 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.0,>=0.5.0; extra == \"cuda12\"->jax[cuda12]) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12>=12.1.105 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.0,>=0.5.0; extra == \"cuda12\"->jax[cuda12]) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12<10.0,>=9.1 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.0,>=0.5.0; extra == \"cuda12\"->jax[cuda12]) (9.7.0.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu12>=11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.0,>=0.5.0; extra == \"cuda12\"->jax[cuda12]) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12>=11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.0,>=0.5.0; extra == \"cuda12\"->jax[cuda12]) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12>=12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.0,>=0.5.0; extra == \"cuda12\"->jax[cuda12]) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-nccl-cu12>=2.18.1 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.0,>=0.5.0; extra == \"cuda12\"->jax[cuda12]) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12>=12.1.105 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.0,>=0.5.0; extra == \"cuda12\"->jax[cuda12]) (12.8.61)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install playground\n",
    "%pip install -U \"jax[cuda12]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WT2lN73AIHjJ"
   },
   "outputs": [],
   "source": [
    "!#@title Import Dependencies and Set Environment\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "import logging\n",
    "\n",
    "# Configure logging for Colab\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lcFDj_N1ILlB",
    "outputId": "012db6e8-7be1-4473-b160-8b29303af71c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train_zbot.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_zbot.py\n",
    "\n",
    "#######################\n",
    "# Setup & Dependencies\n",
    "#######################\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import jax\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ml_collections import config_dict\n",
    "from playground.zbot import joystick as zbot_joystick\n",
    "from playground.zbot import randomize as zbot_randomize\n",
    "from playground.zbot import zbot_constants\n",
    "from playground.runner import ZBotRunner\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),\n",
    "        logging.FileHandler('zbot_training.log')\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "########################\n",
    "# Training Configuration\n",
    "########################\n",
    "\n",
    "def create_training_args(task=\"flat_terrain\", load_existing=False):\n",
    "    \"\"\"Create training arguments with enhanced settings\"\"\"\n",
    "    args = argparse.Namespace(\n",
    "        env=\"ZbotJoystickFlatTerrain\",\n",
    "        task=task,\n",
    "        debug=False,\n",
    "        save_model=True,\n",
    "        load_model=load_existing,\n",
    "        seed=42,\n",
    "        num_episodes=3,\n",
    "        episode_length=3000,\n",
    "        x_vel=1.0,\n",
    "        y_vel=0.0,\n",
    "        yaw_vel=0.0\n",
    "    )\n",
    "    return args\n",
    "\n",
    "def plot_training_progress(runner, title):\n",
    "    \"\"\"Plot training progress with error bands\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(runner.x_data, runner.y_data, label='Mean Reward')\n",
    "    plt.fill_between(\n",
    "        runner.x_data,\n",
    "        np.array(runner.y_data) - np.array(runner.y_dataerr),\n",
    "        np.array(runner.y_data) + np.array(runner.y_dataerr),\n",
    "        alpha=0.2,\n",
    "        label='Std Dev'\n",
    "    )\n",
    "    plt.xlabel('Training Steps')\n",
    "    plt.ylabel('Episode Reward')\n",
    "    plt.title(f'Training Progress: {title}')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{title.lower().replace(\" \", \"_\")}_progress.png')\n",
    "    plt.close()\n",
    "\n",
    "def save_training_metrics(runner, filename):\n",
    "    \"\"\"Save training metrics for later analysis\"\"\"\n",
    "    metrics = {\n",
    "        'steps': runner.x_data,\n",
    "        'rewards': runner.y_data,\n",
    "        'reward_std': runner.y_dataerr,\n",
    "        'training_time': (runner.times[-1] - runner.times[0]).total_seconds()\n",
    "    }\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(metrics, f)\n",
    "\n",
    "#############################\n",
    "# Flat Terrain Training Phase\n",
    "#############################\n",
    "\n",
    "def train_flat_terrain():\n",
    "    \"\"\"Train the initial policy on flat terrain\"\"\"\n",
    "    logger.info(\"=\" * 50)\n",
    "    logger.info(\"Starting flat terrain training phase\")\n",
    "    logger.info(\"=\" * 50)\n",
    "\n",
    "    # Initialize runner with flat terrain config\n",
    "    args = create_training_args(task=\"flat_terrain\", load_existing=False)\n",
    "    logger.info(\"Training configuration:\")\n",
    "    for key, value in vars(args).items():\n",
    "        logger.info(f\"  {key}: {value}\")\n",
    "\n",
    "    runner = ZBotRunner(args, logger)\n",
    "\n",
    "    # Train policy\n",
    "    logger.info(\"Beginning training loop...\")\n",
    "    runner.train()\n",
    "\n",
    "    # Log training statistics\n",
    "    logger.info(\"Training completed. Final statistics:\")\n",
    "    logger.info(f\"  Total steps: {len(runner.x_data)}\")\n",
    "    logger.info(f\"  Final reward: {runner.y_data[-1]:.2f} ± {runner.y_dataerr[-1]:.2f}\")\n",
    "    logger.info(f\"  Training time: {(runner.times[-1] - runner.times[0]).total_seconds():.2f}s\")\n",
    "\n",
    "    # Plot and save results\n",
    "    logger.info(\"Saving training visualizations and metrics...\")\n",
    "    plot_training_progress(runner, \"Flat Terrain Training\")\n",
    "    save_training_metrics(runner, \"flat_terrain_metrics.pkl\")\n",
    "\n",
    "    # Evaluate policy\n",
    "    logger.info(\"Starting flat terrain policy evaluation...\")\n",
    "    runner.evaluate()\n",
    "\n",
    "    return runner\n",
    "\n",
    "##############################\n",
    "# Rough Terrain Training Phase\n",
    "##############################\n",
    "\n",
    "def train_rough_terrain(flat_terrain_runner):\n",
    "    \"\"\"Adapt the policy to rough terrain\"\"\"\n",
    "    logger.info(\"=\" * 50)\n",
    "    logger.info(\"Starting rough terrain adaptation phase\")\n",
    "    logger.info(\"=\" * 50)\n",
    "\n",
    "    # Initialize runner with rough terrain config\n",
    "    args = create_training_args(task=\"rough_terrain\", load_existing=True)\n",
    "    logger.info(\"Training configuration:\")\n",
    "    for key, value in vars(args).items():\n",
    "        logger.info(f\"  {key}: {value}\")\n",
    "\n",
    "    runner = ZBotRunner(args, logger)\n",
    "\n",
    "    # Load flat terrain policy\n",
    "    logger.info(\"Loading pre-trained flat terrain policy...\")\n",
    "    runner.params = flat_terrain_runner.params\n",
    "\n",
    "    # Continue training on rough terrain\n",
    "    logger.info(\"Beginning rough terrain adaptation...\")\n",
    "    runner.train()\n",
    "\n",
    "    # Log training statistics\n",
    "    logger.info(\"Adaptation completed. Final statistics:\")\n",
    "    logger.info(f\"  Total steps: {len(runner.x_data)}\")\n",
    "    logger.info(f\"  Final reward: {runner.y_data[-1]:.2f} ± {runner.y_dataerr[-1]:.2f}\")\n",
    "    logger.info(f\"  Training time: {(runner.times[-1] - runner.times[0]).total_seconds():.2f}s\")\n",
    "\n",
    "    # Plot and save results\n",
    "    logger.info(\"Saving training visualizations and metrics...\")\n",
    "    plot_training_progress(runner, \"Rough Terrain Training\")\n",
    "    save_training_metrics(runner, \"rough_terrain_metrics.pkl\")\n",
    "\n",
    "    # Evaluate policy\n",
    "    logger.info(\"Starting rough terrain policy evaluation...\")\n",
    "    runner.evaluate()\n",
    "\n",
    "    return runner\n",
    "\n",
    "#######################\n",
    "# Analysis & Evaluation\n",
    "#######################\n",
    "\n",
    "def analyze_performance(flat_metrics, rough_metrics):\n",
    "    \"\"\"Compare and analyze training performance\"\"\"\n",
    "    logger.info(\"=\" * 50)\n",
    "    logger.info(\"Performance Analysis\")\n",
    "    logger.info(\"=\" * 50)\n",
    "\n",
    "    # Print summary statistics\n",
    "    logger.info(\"Training Summary:\")\n",
    "    logger.info(\"Flat Terrain:\")\n",
    "    logger.info(f\"  Training time: {flat_metrics['training_time']:.2f}s\")\n",
    "    logger.info(f\"  Final reward: {flat_metrics['rewards'][-1]:.2f} ± {flat_metrics['reward_std'][-1]:.2f}\")\n",
    "    logger.info(f\"  Peak reward: {max(flat_metrics['rewards']):.2f}\")\n",
    "\n",
    "    logger.info(\"Rough Terrain:\")\n",
    "    logger.info(f\"  Training time: {rough_metrics['training_time']:.2f}s\")\n",
    "    logger.info(f\"  Final reward: {rough_metrics['rewards'][-1]:.2f} ± {rough_metrics['reward_std'][-1]:.2f}\")\n",
    "    logger.info(f\"  Peak reward: {max(rough_metrics['rewards']):.2f}\")\n",
    "\n",
    "    # Create comparison plot\n",
    "    logger.info(\"Generating performance comparison plot...\")\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot flat terrain progress\n",
    "    plt.plot(flat_metrics['steps'], flat_metrics['rewards'],\n",
    "             label='Flat Terrain', color='blue')\n",
    "    plt.fill_between(\n",
    "        flat_metrics['steps'],\n",
    "        np.array(flat_metrics['rewards']) - np.array(flat_metrics['reward_std']),\n",
    "        np.array(flat_metrics['rewards']) + np.array(flat_metrics['reward_std']),\n",
    "        alpha=0.2,\n",
    "        color='blue'\n",
    "    )\n",
    "\n",
    "    # Plot rough terrain progress\n",
    "    plt.plot(rough_metrics['steps'], rough_metrics['rewards'],\n",
    "             label='Rough Terrain', color='red')\n",
    "    plt.fill_between(\n",
    "        rough_metrics['steps'],\n",
    "        np.array(rough_metrics['rewards']) - np.array(rough_metrics['reward_std']),\n",
    "        np.array(rough_metrics['rewards']) + np.array(rough_metrics['reward_std']),\n",
    "        alpha=0.2,\n",
    "        color='red'\n",
    "    )\n",
    "\n",
    "    plt.xlabel('Training Steps')\n",
    "    plt.ylabel('Episode Reward')\n",
    "    plt.title('Training Progress Comparison')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig('training_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "##############\n",
    "# Main Script\n",
    "##############\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main training pipeline\"\"\"\n",
    "    logger.info(\"=\" * 50)\n",
    "    logger.info(\"Starting ZBot Training Pipeline\")\n",
    "    logger.info(\"=\" * 50)\n",
    "\n",
    "    # Create output directory\n",
    "    output_dir = Path(\"outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    logger.info(f\"Created output directory: {output_dir}\")\n",
    "\n",
    "    try:\n",
    "        # Train on flat terrain\n",
    "        logger.info(\"Starting flat terrain training phase...\")\n",
    "        flat_runner = train_flat_terrain()\n",
    "\n",
    "        # Train on rough terrain\n",
    "        logger.info(\"Starting rough terrain adaptation phase...\")\n",
    "        rough_runner = train_rough_terrain(flat_runner)\n",
    "\n",
    "        # Load and analyze results\n",
    "        logger.info(\"Loading training metrics for analysis...\")\n",
    "        with open(\"flat_terrain_metrics.pkl\", 'rb') as f:\n",
    "            flat_metrics = pickle.load(f)\n",
    "        with open(\"rough_terrain_metrics.pkl\", 'rb') as f:\n",
    "            rough_metrics = pickle.load(f)\n",
    "\n",
    "        analyze_performance(flat_metrics, rough_metrics)\n",
    "\n",
    "        logger.info(\"Training pipeline completed successfully!\")\n",
    "        logger.info(\"Check the outputs directory for results and visualizations.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during training: {str(e)}\", exc_info=True)\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (2.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan\n",
      "/home/jovyan/mujoco_playground/playground/zbot/:\n",
      "base.py  __init__.py  joystick.py  randomize.py  xmls  zbot_constants.py\n",
      "\n",
      "/home/jovyan/mujoco_playground/playground/zbot/xmls:\n",
      "assets\t\t\t\t     scene_mjx_feetonly_rough_terrain.xml\n",
      "scene_mjx_feetonly_flat_terrain.xml  zbot_feet_only.xml\n",
      "\n",
      "/home/jovyan/mujoco_playground/playground/zbot/xmls/assets:\n",
      "hfield.png  rocky_texture.png\n",
      "Import successful!\n"
     ]
    }
   ],
   "source": [
    "#@title Check Repository Structure\n",
    "!pwd\n",
    "!ls -R /home/jovyan/mujoco_playground/playground/zbot/\n",
    "!python3 -c \"from mujoco_playground._src import mjx_env; print('Import successful!')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "%%capture\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Define paths\n",
    "EXTERNAL_DEPS_PATH = Path.home() / \".mujoco_playground\" / \"external\"\n",
    "MENAGERIE_PATH = EXTERNAL_DEPS_PATH / \"mujoco_menagerie\"\n",
    "MENAGERIE_COMMIT_SHA = \"main\"  # or specific SHA if needed\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "EXTERNAL_DEPS_PATH.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "def download_menagerie():\n",
    "    \"\"\"Download mujoco_menagerie with better error handling\"\"\"\n",
    "    print(\"Attempting to download mujoco_menagerie...\")\n",
    "    \n",
    "    # Remove existing directory if it exists\n",
    "    if MENAGERIE_PATH.exists():\n",
    "        print(\"Removing existing mujoco_menagerie directory...\")\n",
    "        subprocess.run([\"rm\", \"-rf\", str(MENAGERIE_PATH)])\n",
    "    \n",
    "    try:\n",
    "        # Try using git clone\n",
    "        print(\"Attempting git clone...\")\n",
    "        subprocess.run(\n",
    "            [\"git\", \"clone\", \"--depth\", \"1\", \n",
    "             \"https://github.com/deepmind/mujoco_menagerie.git\",\n",
    "             str(MENAGERIE_PATH)],\n",
    "            check=True,\n",
    "            capture_output=True\n",
    "        )\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"Git clone failed, trying alternative download method...\")\n",
    "        # Alternative: Download using wget/curl\n",
    "        try:\n",
    "            subprocess.run([\n",
    "                \"wget\", \n",
    "                \"https://github.com/deepmind/mujoco_menagerie/archive/refs/heads/main.zip\",\n",
    "                \"-O\", \"/tmp/menagerie.zip\"\n",
    "            ], check=True)\n",
    "            \n",
    "            # Extract the downloaded zip\n",
    "            subprocess.run([\"unzip\", \"/tmp/menagerie.zip\", \"-d\", \"/tmp\"], check=True)\n",
    "            \n",
    "            # Move to correct location\n",
    "            subprocess.run([\n",
    "                \"mv\", \n",
    "                \"/tmp/mujoco_menagerie-main\", \n",
    "                str(MENAGERIE_PATH)\n",
    "            ], check=True)\n",
    "            \n",
    "            # Cleanup\n",
    "            os.remove(\"/tmp/menagerie.zip\")\n",
    "            print(\"Successfully downloaded mujoco_menagerie using alternative method\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error downloading mujoco_menagerie: {e}\")\n",
    "            raise\n",
    "\n",
    "# Try to download\n",
    "try:\n",
    "    download_menagerie()\n",
    "except Exception as e:\n",
    "    print(f\"Failed to download mujoco_menagerie: {e}\")\n",
    "    print(\"Please check your internet connection and try again\")\n",
    "    raise\n",
    "\n",
    "# Verify the installation\n",
    "if MENAGERIE_PATH.exists():\n",
    "    print(\"mujoco_menagerie successfully installed\")\n",
    "else:\n",
    "    print(\"Failed to install mujoco_menagerie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "sfXYFaUQJB4Y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 17:45:28,491 - INFO - Handler \"orbax.checkpoint._src.handlers.array_checkpoint_handler.ArrayCheckpointHandler\" already exists in the registry with associated type <class 'orbax.checkpoint._src.handlers.array_checkpoint_handler.ArrayCheckpointHandler'>. Skipping registration.\n",
      "2025-01-30 17:45:28,494 - INFO - Handler \"orbax.checkpoint._src.handlers.proto_checkpoint_handler.ProtoCheckpointHandler\" already exists in the registry with associated type <class 'orbax.checkpoint._src.handlers.proto_checkpoint_handler.ProtoCheckpointHandler'>. Skipping registration.\n",
      "2025-01-30 17:45:28,496 - INFO - Handler \"orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler\" already exists in the registry with associated type <class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler'>. Skipping registration.\n",
      "2025-01-30 17:45:28,499 - INFO - Handler \"orbax.checkpoint._src.handlers.base_pytree_checkpoint_handler.BasePyTreeCheckpointHandler\" already exists in the registry with associated type <class 'orbax.checkpoint._src.handlers.base_pytree_checkpoint_handler.BasePyTreeCheckpointHandler'>. Skipping registration.\n",
      "2025-01-30 17:45:28,500 - INFO - Handler \"orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler\" already exists in the registry with associated type <class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler'>. Skipping registration.\n",
      "2025-01-30 17:45:28,503 - INFO - Handler \"orbax.checkpoint._src.handlers.standard_checkpoint_handler.StandardCheckpointHandler\" already exists in the registry with associated type <class 'orbax.checkpoint._src.handlers.standard_checkpoint_handler.StandardCheckpointHandler'>. Skipping registration.\n",
      "2025-01-30 17:45:28,504 - INFO - Handler \"orbax.checkpoint._src.handlers.random_key_checkpoint_handler.JaxRandomKeyCheckpointHandler\" already exists in the registry with associated type <class 'orbax.checkpoint._src.handlers.random_key_checkpoint_handler.JaxRandomKeyCheckpointHandler'>. Skipping registration.\n",
      "2025-01-30 17:45:28,505 - INFO - Handler \"orbax.checkpoint._src.handlers.random_key_checkpoint_handler.NumpyRandomKeyCheckpointHandler\" already exists in the registry with associated type <class 'orbax.checkpoint._src.handlers.random_key_checkpoint_handler.NumpyRandomKeyCheckpointHandler'>. Skipping registration.\n",
      "2025-01-30 17:45:28,513 - INFO - Handler \"orbax.checkpoint.test_utils.ErrorCheckpointHandler\" already exists in the registry with associated type <class 'orbax.checkpoint.test_utils.ErrorCheckpointHandler'>. Skipping registration.\n"
     ]
    }
   ],
   "source": [
    "#@title Training Configuration\n",
    "#@markdown Adjust training parameters here\n",
    "NUM_EPISODES = 100  #@param {type:\"integer\"}\n",
    "EPISODE_LENGTH = 5000  #@param {type:\"integer\"}\n",
    "TASK = \"flat_terrain\"  #@param [\"flat_terrain\", \"rough_terrain\"]\n",
    "LOAD_EXISTING = False  #@param {type:\"boolean\"}\n",
    "\n",
    "# Additional training parameters\n",
    "CURRICULUM_LEARNING = True  #@param {type:\"boolean\"}\n",
    "INITIAL_ROUGHNESS = 0.0  #@param {type:\"number\"}\n",
    "FINAL_ROUGHNESS = 1.0  #@param {type:\"number\"}\n",
    "ROUGHNESS_INCREMENT = 0.1  #@param {type:\"number\"}\n",
    "MIN_SUCCESS_RATE = 0.7  #@param {type:\"number\"}\n",
    "\n",
    "# Domain randomization parameters\n",
    "RANDOMIZE_MASS = True  #@param {type:\"boolean\"}\n",
    "MASS_RANGE_MIN = 0.8  #@param {type:\"number\"}\n",
    "MASS_RANGE_MAX = 1.2  #@param {type:\"number\"}\n",
    "RANDOMIZE_FRICTION = True  #@param {type:\"boolean\"}\n",
    "FRICTION_RANGE_MIN = 0.8  #@param {type:\"number\"}\n",
    "FRICTION_RANGE_MAX = 1.2  #@param {type:\"number\"}\n",
    "\n",
    "from train_zbot import create_training_args, train_flat_terrain, train_rough_terrain, train_with_curriculum\n",
    "\n",
    "args = create_training_args(\n",
    "    task=TASK,\n",
    "    load_existing=LOAD_EXISTING\n",
    ")\n",
    "\n",
    "# Update args with UI parameters\n",
    "args.num_episodes = NUM_EPISODES\n",
    "args.episode_length = EPISODE_LENGTH\n",
    "args.curriculum = CURRICULUM_LEARNING\n",
    "args.initial_roughness = INITIAL_ROUGHNESS\n",
    "args.final_roughness = FINAL_ROUGHNESS\n",
    "args.roughness_increment = ROUGHNESS_INCREMENT\n",
    "args.min_success_rate = MIN_SUCCESS_RATE\n",
    "args.randomize_mass = RANDOMIZE_MASS\n",
    "args.mass_range = (MASS_RANGE_MIN, MASS_RANGE_MAX)\n",
    "args.randomize_friction = RANDOMIZE_FRICTION\n",
    "args.friction_range = (FRICTION_RANGE_MIN, FRICTION_RANGE_MAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1nIiAxJZy6n",
    "outputId": "117ffc48-6b84-489a-83cc-5ed40c1cf5ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 17:45:28,522 - INFO - ==================================================\n",
      "2025-01-30 17:45:28,523 - INFO - Starting flat terrain training phase\n",
      "2025-01-30 17:45:28,523 - INFO - ==================================================\n",
      "2025-01-30 17:45:28,524 - INFO - Training configuration:\n",
      "2025-01-30 17:45:28,524 - INFO -   env: ZbotJoystickFlatTerrain\n",
      "2025-01-30 17:45:28,524 - INFO -   task: flat_terrain\n",
      "2025-01-30 17:45:28,524 - INFO -   debug: False\n",
      "2025-01-30 17:45:28,524 - INFO -   save_model: True\n",
      "2025-01-30 17:45:28,525 - INFO -   load_model: False\n",
      "2025-01-30 17:45:28,525 - INFO -   seed: 42\n",
      "2025-01-30 17:45:28,525 - INFO -   num_episodes: 3\n",
      "2025-01-30 17:45:28,525 - INFO -   episode_length: 3000\n",
      "2025-01-30 17:45:28,526 - INFO -   x_vel: 1.0\n",
      "2025-01-30 17:45:28,526 - INFO -   y_vel: 0.0\n",
      "2025-01-30 17:45:28,526 - INFO -   yaw_vel: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for XML file at: playground/zbot/xmls/scene_mjx_feetonly_rough_terrain.xml\n",
      "File exists: True\n",
      "Starting rough terrain training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 17:45:29,555 - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "2025-01-30 17:45:29,556 - INFO - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
      "2025-01-30 17:45:31,290 - INFO - RL config: action_repeat: 1\n",
      "batch_size: 512\n",
      "clipping_epsilon: 0.2\n",
      "discounting: 0.97\n",
      "entropy_cost: 0.01\n",
      "episode_length: 1000\n",
      "learning_rate: 0.0003\n",
      "max_grad_norm: 1.0\n",
      "network_factory:\n",
      "  policy_hidden_layer_sizes: &id001 !!python/tuple\n",
      "  - 1024\n",
      "  - 512\n",
      "  - 256\n",
      "  policy_obs_key: state\n",
      "  value_hidden_layer_sizes: *id001\n",
      "  value_obs_key: privileged_state\n",
      "normalize_observations: true\n",
      "num_envs: 16384\n",
      "num_evals: 20\n",
      "num_minibatches: 32\n",
      "num_resets_per_eval: 2\n",
      "num_timesteps: 200000000\n",
      "num_updates_per_batch: 8\n",
      "reward_scaling: 1.0\n",
      "unroll_length: 20\n",
      "\n",
      "2025-01-30 17:45:31,291 - INFO - Beginning training loop...\n",
      "2025-01-30 17:45:31,291 - INFO - Device count: 1, process count: 1 (id 0), local device count: 1, devices to be used count: 1\n",
      "/usr/local/lib/python3.10/dist-packages/jax/_src/interpreters/xla.py:132: RuntimeWarning: overflow encountered in cast\n",
      "  return np.asarray(x, dtypes.canonicalize_dtype(x.dtype))\n",
      "2025-01-30 17:47:24,739 - INFO - {'eval/walltime': 72.70052075386047, 'eval/episode_reward': Array(0.38220376, dtype=float32), 'eval/episode_reward/action_rate': Array(-4.1172786, dtype=float32), 'eval/episode_reward/alive': Array(39.015625, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-108.28167, dtype=float32), 'eval/episode_reward/base_height': Array(-0.30323058, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.4476409, dtype=float32), 'eval/episode_reward/energy': Array(-0.04587334, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.1331251, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.26606777, dtype=float32), 'eval/episode_reward/feet_height': Array(0.30436802, dtype=float32), 'eval/episode_reward/feet_phase': Array(13.548263, dtype=float32), 'eval/episode_reward/feet_slip': Array(-15.800842, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-2.8390224, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-3.5021753, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-13.796495, dtype=float32), 'eval/episode_reward/orientation': Array(-16.497387, dtype=float32), 'eval/episode_reward/pose': Array(-6.075351, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00299016, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(9.423639, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(9.434233, dtype=float32), 'eval/episode_swing_peak': Array(0.2288183, dtype=float32), 'eval/episode_reward_std': Array(0.5353117, dtype=float32), 'eval/episode_reward/action_rate_std': Array(2.003824, dtype=float32), 'eval/episode_reward/alive_std': Array(18.22043, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(20.625853, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.07236722, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(1.1797787, dtype=float32), 'eval/episode_reward/energy_std': Array(0.01409506, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(0.93476087, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.07227258, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.21014662, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(5.133508, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(4.8549356, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(1.8021898, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(2.3329418, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(4.948356, dtype=float32), 'eval/episode_reward/orientation_std': Array(3.3251626, dtype=float32), 'eval/episode_reward/pose_std': Array(4.6188035, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00135868, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(8.787769, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(10.4068, dtype=float32), 'eval/episode_swing_peak_std': Array(0.17956188, dtype=float32), 'eval/avg_episode_length': Array(39.015625, dtype=float32), 'eval/epoch_eval_time': 72.70052075386047, 'eval/sps': 1760.6476359827598}\n",
      "2025-01-30 17:47:24,945 - INFO - starting iteration 0 113.65398907661438\n",
      "2025-01-30 17:49:06,523 - INFO - {'eval/walltime': 82.63165545463562, 'training/sps': np.float64(549811.2542675333), 'training/walltime': 91.23123502731323, 'training/entropy_loss': Array(-0.03791063, dtype=float32), 'training/policy_loss': Array(0.04356765, dtype=float32), 'training/total_loss': Array(2.0415676, dtype=float32), 'training/v_loss': Array(2.0359106, dtype=float32), 'eval/episode_reward': Array(0.44340593, dtype=float32), 'eval/episode_reward/action_rate': Array(-6.599493, dtype=float32), 'eval/episode_reward/alive': Array(43.523438, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-109.52706, dtype=float32), 'eval/episode_reward/base_height': Array(-0.31533647, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.4755796, dtype=float32), 'eval/episode_reward/energy': Array(-0.06516477, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.2231251, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.28428686, dtype=float32), 'eval/episode_reward/feet_height': Array(0.31633887, dtype=float32), 'eval/episode_reward/feet_phase': Array(14.910247, dtype=float32), 'eval/episode_reward/feet_slip': Array(-15.928413, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-3.9302967, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-3.4281938, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-13.800794, dtype=float32), 'eval/episode_reward/orientation': Array(-17.286331, dtype=float32), 'eval/episode_reward/pose': Array(-7.626272, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00398947, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(9.175167, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(10.98949, dtype=float32), 'eval/episode_swing_peak': Array(0.24851781, dtype=float32), 'eval/episode_reward_std': Array(1.1298985, dtype=float32), 'eval/episode_reward/action_rate_std': Array(7.4569206, dtype=float32), 'eval/episode_reward/alive_std': Array(50.391125, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(20.097866, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.15149146, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(1.2516214, dtype=float32), 'eval/episode_reward/energy_std': Array(0.03868869, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.2463207, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.14298321, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.329219, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(13.35417, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(5.331471, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(6.313675, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(2.769643, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(4.9637747, dtype=float32), 'eval/episode_reward/orientation_std': Array(9.155817, dtype=float32), 'eval/episode_reward/pose_std': Array(8.308984, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00417154, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(12.588854, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(19.257175, dtype=float32), 'eval/episode_swing_peak_std': Array(0.16763346, dtype=float32), 'eval/avg_episode_length': Array(43.523438, dtype=float32), 'eval/epoch_eval_time': 9.931134700775146, 'eval/sps': 12888.758823300355}\n",
      "2025-01-30 17:49:06,598 - INFO - starting iteration 1 215.30679726600647\n",
      "2025-01-30 17:49:57,114 - INFO - {'eval/walltime': 92.59491205215454, 'training/sps': np.float64(550749.4111816054), 'training/walltime': 131.7299234867096, 'training/entropy_loss': Array(-0.05423793, dtype=float32), 'training/policy_loss': Array(-0.03356366, dtype=float32), 'training/total_loss': Array(-0.08692096, dtype=float32), 'training/v_loss': Array(0.00088063, dtype=float32), 'eval/episode_reward': Array(0.6574694, dtype=float32), 'eval/episode_reward/action_rate': Array(-6.034008, dtype=float32), 'eval/episode_reward/alive': Array(45.039062, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-112.58707, dtype=float32), 'eval/episode_reward/base_height': Array(-0.321403, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.3977268, dtype=float32), 'eval/episode_reward/energy': Array(-0.05604475, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.3631251, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.29880923, dtype=float32), 'eval/episode_reward/feet_height': Array(0.36047107, dtype=float32), 'eval/episode_reward/feet_phase': Array(15.663132, dtype=float32), 'eval/episode_reward/feet_slip': Array(-16.37947, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-3.2179132, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-3.1324267, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-15.33076, dtype=float32), 'eval/episode_reward/orientation': Array(-15.941459, dtype=float32), 'eval/episode_reward/pose': Array(-6.2728996, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00391458, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(12.248344, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(14.540623, dtype=float32), 'eval/episode_swing_peak': Array(0.24186063, dtype=float32), 'eval/episode_reward_std': Array(1.5973743, dtype=float32), 'eval/episode_reward/action_rate_std': Array(5.7430215, dtype=float32), 'eval/episode_reward/alive_std': Array(42.18586, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(20.805996, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.10854684, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(1.212195, dtype=float32), 'eval/episode_reward/energy_std': Array(0.02695835, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.2138535, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.15832882, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.26077998, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(11.350408, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(4.8689575, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(3.435449, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(2.1140254, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(4.655789, dtype=float32), 'eval/episode_reward/orientation_std': Array(3.2577927, dtype=float32), 'eval/episode_reward/pose_std': Array(5.1441784, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00356889, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(17.500584, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(32.144474, dtype=float32), 'eval/episode_swing_peak_std': Array(0.16881385, dtype=float32), 'eval/avg_episode_length': Array(45.039062, dtype=float32), 'eval/epoch_eval_time': 9.963256597518921, 'eval/sps': 12847.20500241607}\n",
      "2025-01-30 17:49:57,196 - INFO - starting iteration 2 265.90482354164124\n",
      "2025-01-30 17:50:47,804 - INFO - {'eval/walltime': 102.55023407936096, 'training/sps': np.float64(549106.8535681306), 'training/walltime': 172.3271176815033, 'training/entropy_loss': Array(-0.05070777, dtype=float32), 'training/policy_loss': Array(-0.03524573, dtype=float32), 'training/total_loss': Array(-0.08511426, dtype=float32), 'training/v_loss': Array(0.00083923, dtype=float32), 'eval/episode_reward': Array(1.3994844, dtype=float32), 'eval/episode_reward/action_rate': Array(-8.125837, dtype=float32), 'eval/episode_reward/alive': Array(68.22656, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-111.94348, dtype=float32), 'eval/episode_reward/base_height': Array(-0.3651982, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.7894835, dtype=float32), 'eval/episode_reward/energy': Array(-0.0699635, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.205625, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.3397569, dtype=float32), 'eval/episode_reward/feet_height': Array(0.35067013, dtype=float32), 'eval/episode_reward/feet_phase': Array(21.17833, dtype=float32), 'eval/episode_reward/feet_slip': Array(-15.9369335, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-4.4089794, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-4.424964, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-14.744606, dtype=float32), 'eval/episode_reward/orientation': Array(-15.84365, dtype=float32), 'eval/episode_reward/pose': Array(-8.418012, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00574951, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(19.279211, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(22.1213, dtype=float32), 'eval/episode_swing_peak': Array(0.28404903, dtype=float32), 'eval/episode_reward_std': Array(3.674757, dtype=float32), 'eval/episode_reward/action_rate_std': Array(11.400401, dtype=float32), 'eval/episode_reward/alive_std': Array(98.15853, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(20.691565, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.2319393, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(2.9263947, dtype=float32), 'eval/episode_reward/energy_std': Array(0.04950904, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.3673767, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.23608707, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.3404426, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(26.061983, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(6.030565, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(5.879667, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(3.9042997, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(4.9080386, dtype=float32), 'eval/episode_reward/orientation_std': Array(2.9537513, dtype=float32), 'eval/episode_reward/pose_std': Array(12.158653, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00770447, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(37.286526, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(69.38065, dtype=float32), 'eval/episode_swing_peak_std': Array(0.20205744, dtype=float32), 'eval/avg_episode_length': Array(68.22656, dtype=float32), 'eval/epoch_eval_time': 9.955322027206421, 'eval/sps': 12857.44445535714}\n",
      "2025-01-30 17:50:47,886 - INFO - starting iteration 3 316.59433794021606\n",
      "2025-01-30 17:51:38,405 - INFO - {'eval/walltime': 112.48901152610779, 'training/sps': np.float64(549667.4338313156), 'training/walltime': 212.8496789932251, 'training/entropy_loss': Array(-0.0455047, dtype=float32), 'training/policy_loss': Array(-0.03473617, dtype=float32), 'training/total_loss': Array(-0.07939513, dtype=float32), 'training/v_loss': Array(0.00084574, dtype=float32), 'eval/episode_reward': Array(1.8828166, dtype=float32), 'eval/episode_reward/action_rate': Array(-9.148376, dtype=float32), 'eval/episode_reward/alive': Array(83.02344, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-115.573364, dtype=float32), 'eval/episode_reward/base_height': Array(-0.4047927, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.7750065, dtype=float32), 'eval/episode_reward/energy': Array(-0.07269264, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.2537501, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.37036112, dtype=float32), 'eval/episode_reward/feet_height': Array(0.33984068, dtype=float32), 'eval/episode_reward/feet_phase': Array(25.367432, dtype=float32), 'eval/episode_reward/feet_slip': Array(-17.437336, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-5.2305236, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-4.683447, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-16.145678, dtype=float32), 'eval/episode_reward/orientation': Array(-15.666333, dtype=float32), 'eval/episode_reward/pose': Array(-9.744011, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00684077, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(23.127808, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(27.946796, dtype=float32), 'eval/episode_swing_peak': Array(0.25772026, dtype=float32), 'eval/episode_reward_std': Array(3.501538, dtype=float32), 'eval/episode_reward/action_rate_std': Array(11.9375, dtype=float32), 'eval/episode_reward/alive_std': Array(108.59172, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(20.12505, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.23782146, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(1.8368778, dtype=float32), 'eval/episode_reward/energy_std': Array(0.05006262, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.1733758, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.25579083, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.26415548, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(28.90489, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(6.7231407, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(7.341837, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(4.651885, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(5.2246647, dtype=float32), 'eval/episode_reward/orientation_std': Array(3.1653936, dtype=float32), 'eval/episode_reward/pose_std': Array(10.0407095, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00826579, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(34.35345, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(48.16654, dtype=float32), 'eval/episode_swing_peak_std': Array(0.18220487, dtype=float32), 'eval/avg_episode_length': Array(83.02344, dtype=float32), 'eval/epoch_eval_time': 9.938777446746826, 'eval/sps': 12878.847593261798}\n",
      "2025-01-30 17:51:38,486 - INFO - starting iteration 4 367.1948516368866\n",
      "2025-01-30 17:52:29,150 - INFO - {'eval/walltime': 122.45046877861023, 'training/sps': np.float64(547967.7885472904), 'training/walltime': 253.49627423286438, 'training/entropy_loss': Array(-0.04222981, dtype=float32), 'training/policy_loss': Array(-0.03507475, dtype=float32), 'training/total_loss': Array(-0.07644747, dtype=float32), 'training/v_loss': Array(0.00085709, dtype=float32), 'eval/episode_reward': Array(1.6897207, dtype=float32), 'eval/episode_reward/action_rate': Array(-7.8438063, dtype=float32), 'eval/episode_reward/alive': Array(74.84375, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-114.12993, dtype=float32), 'eval/episode_reward/base_height': Array(-0.38659495, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.4668865, dtype=float32), 'eval/episode_reward/energy': Array(-0.06869169, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.1868751, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.36074945, dtype=float32), 'eval/episode_reward/feet_height': Array(0.33165377, dtype=float32), 'eval/episode_reward/feet_phase': Array(23.50973, dtype=float32), 'eval/episode_reward/feet_slip': Array(-16.692093, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-4.495288, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-4.233426, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-16.301718, dtype=float32), 'eval/episode_reward/orientation': Array(-15.642293, dtype=float32), 'eval/episode_reward/pose': Array(-6.917859, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00607454, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(20.327879, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(26.374737, dtype=float32), 'eval/episode_swing_peak': Array(0.30004168, dtype=float32), 'eval/episode_reward_std': Array(3.7365813, dtype=float32), 'eval/episode_reward/action_rate_std': Array(10.96358, dtype=float32), 'eval/episode_reward/alive_std': Array(108.367386, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(17.399551, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.24595743, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(1.3306203, dtype=float32), 'eval/episode_reward/energy_std': Array(0.04701712, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.0693352, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.2600265, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.2564249, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(29.018839, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(7.464163, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(6.631572, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(4.075322, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(4.512522, dtype=float32), 'eval/episode_reward/orientation_std': Array(2.921259, dtype=float32), 'eval/episode_reward/pose_std': Array(6.7105765, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00794187, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(33.89965, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(57.8537, dtype=float32), 'eval/episode_swing_peak_std': Array(0.21597193, dtype=float32), 'eval/avg_episode_length': Array(74.84375, dtype=float32), 'eval/epoch_eval_time': 9.961457252502441, 'eval/sps': 12849.525602074416}\n",
      "2025-01-30 17:52:29,235 - INFO - starting iteration 5 417.9436113834381\n",
      "2025-01-30 17:53:19,815 - INFO - {'eval/walltime': 132.40712809562683, 'training/sps': np.float64(548235.6596012264), 'training/walltime': 294.06102180480957, 'training/entropy_loss': Array(-0.04464711, dtype=float32), 'training/policy_loss': Array(-0.0009069, dtype=float32), 'training/total_loss': Array(870468.7, dtype=float32), 'training/v_loss': Array(870468.8, dtype=float32), 'eval/episode_reward': Array(1.3788936, dtype=float32), 'eval/episode_reward/action_rate': Array(-7.2886877, dtype=float32), 'eval/episode_reward/alive': Array(65.38281, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-115.60569, dtype=float32), 'eval/episode_reward/base_height': Array(-0.36614007, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.5708295, dtype=float32), 'eval/episode_reward/energy': Array(-0.06415904, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.3800001, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.33531073, dtype=float32), 'eval/episode_reward/feet_height': Array(0.35502124, dtype=float32), 'eval/episode_reward/feet_phase': Array(21.03217, dtype=float32), 'eval/episode_reward/feet_slip': Array(-16.610052, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-4.523288, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-3.6725779, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-16.144907, dtype=float32), 'eval/episode_reward/orientation': Array(-15.09395, dtype=float32), 'eval/episode_reward/pose': Array(-6.899213, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00530147, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(18.661974, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(21.489424, dtype=float32), 'eval/episode_swing_peak': Array(0.28425395, dtype=float32), 'eval/episode_reward_std': Array(3.3023777, dtype=float32), 'eval/episode_reward/action_rate_std': Array(9.924968, dtype=float32), 'eval/episode_reward/alive_std': Array(91.71424, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(17.814198, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.20578541, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(1.49916, dtype=float32), 'eval/episode_reward/energy_std': Array(0.04315012, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.2905039, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.24656437, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.3288919, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(24.34191, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(6.7752156, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(5.768351, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(3.0688555, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(4.68468, dtype=float32), 'eval/episode_reward/orientation_std': Array(2.2558594, dtype=float32), 'eval/episode_reward/pose_std': Array(6.2044716, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00672022, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(33.429344, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(49.788548, dtype=float32), 'eval/episode_swing_peak_std': Array(0.25959733, dtype=float32), 'eval/avg_episode_length': Array(65.38281, dtype=float32), 'eval/epoch_eval_time': 9.956659317016602, 'eval/sps': 12855.717557920192}\n",
      "2025-01-30 17:53:19,900 - INFO - starting iteration 6 468.6087257862091\n",
      "2025-01-30 17:54:10,506 - INFO - {'eval/walltime': 142.3608922958374, 'training/sps': np.float64(549657.8971835393), 'training/walltime': 334.6568241119385, 'training/entropy_loss': Array(-0.04846249, dtype=float32), 'training/policy_loss': Array(-0.03711022, dtype=float32), 'training/total_loss': Array(-0.08449539, dtype=float32), 'training/v_loss': Array(0.00107731, dtype=float32), 'eval/episode_reward': Array(1.8716121, dtype=float32), 'eval/episode_reward/action_rate': Array(-9.01049, dtype=float32), 'eval/episode_reward/alive': Array(83.57031, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-115.63377, dtype=float32), 'eval/episode_reward/base_height': Array(-0.41133177, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.7499714, dtype=float32), 'eval/episode_reward/energy': Array(-0.06997459, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.2906251, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.37633723, dtype=float32), 'eval/episode_reward/feet_height': Array(0.34516066, dtype=float32), 'eval/episode_reward/feet_phase': Array(25.589802, dtype=float32), 'eval/episode_reward/feet_slip': Array(-17.468214, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-5.5574884, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-4.5596814, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-16.529964, dtype=float32), 'eval/episode_reward/orientation': Array(-15.413387, dtype=float32), 'eval/episode_reward/pose': Array(-8.145991, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-1.984375, dtype=float32), 'eval/episode_reward/torques': Array(-0.00673145, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(23.693897, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(24.346518, dtype=float32), 'eval/episode_swing_peak': Array(0.27143046, dtype=float32), 'eval/episode_reward_std': Array(4.2469006, dtype=float32), 'eval/episode_reward/action_rate_std': Array(13.237269, dtype=float32), 'eval/episode_reward/alive_std': Array(124.699554, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(21.480824, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.2703852, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(1.8789867, dtype=float32), 'eval/episode_reward/energy_std': Array(0.05467798, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.0961009, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.25611678, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.26525223, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(32.81546, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(7.083101, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(7.1694756, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(4.6553235, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(4.5257826, dtype=float32), 'eval/episode_reward/orientation_std': Array(2.3171325, dtype=float32), 'eval/episode_reward/pose_std': Array(8.468476, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0.1760848, dtype=float32), 'eval/episode_reward/torques_std': Array(0.00931736, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(39.08564, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(60.9025, dtype=float32), 'eval/episode_swing_peak_std': Array(0.21120363, dtype=float32), 'eval/avg_episode_length': Array(83.57031, dtype=float32), 'eval/epoch_eval_time': 9.953764200210571, 'eval/sps': 12859.456726661474}\n",
      "2025-01-30 17:54:10,584 - INFO - starting iteration 7 519.2929060459137\n",
      "2025-01-30 17:55:01,139 - INFO - {'eval/walltime': 152.30990147590637, 'training/sps': np.float64(548764.1905396456), 'training/walltime': 375.20213890075684, 'training/entropy_loss': Array(-0.04272429, dtype=float32), 'training/policy_loss': Array(-0.03627614, dtype=float32), 'training/total_loss': Array(-0.07804461, dtype=float32), 'training/v_loss': Array(0.00095582, dtype=float32), 'eval/episode_reward': Array(2.5367632, dtype=float32), 'eval/episode_reward/action_rate': Array(-9.383822, dtype=float32), 'eval/episode_reward/alive': Array(94.15625, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-117.53758, dtype=float32), 'eval/episode_reward/base_height': Array(-0.4265496, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.344363, dtype=float32), 'eval/episode_reward/energy': Array(-0.07576925, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.225625, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.38800126, dtype=float32), 'eval/episode_reward/feet_height': Array(0.36850268, dtype=float32), 'eval/episode_reward/feet_phase': Array(28.265503, dtype=float32), 'eval/episode_reward/feet_slip': Array(-16.814228, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-4.845466, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-5.129739, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-16.233624, dtype=float32), 'eval/episode_reward/orientation': Array(-15.581877, dtype=float32), 'eval/episode_reward/pose': Array(-8.172988, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-1.984375, dtype=float32), 'eval/episode_reward/torques': Array(-0.00745713, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(31.411282, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(37.416725, dtype=float32), 'eval/episode_swing_peak': Array(0.29413113, dtype=float32), 'eval/episode_reward_std': Array(5.267586, dtype=float32), 'eval/episode_reward/action_rate_std': Array(12.239334, dtype=float32), 'eval/episode_reward/alive_std': Array(131.2975, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(23.233944, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.2749947, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(1.6899371, dtype=float32), 'eval/episode_reward/energy_std': Array(0.05081909, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.1512139, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.28830877, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.29550147, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(34.820415, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(7.027492, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(5.593709, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(5.1724005, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(5.289747, dtype=float32), 'eval/episode_reward/orientation_std': Array(3.159189, dtype=float32), 'eval/episode_reward/pose_std': Array(8.283547, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0.1760848, dtype=float32), 'eval/episode_reward/torques_std': Array(0.00926832, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(52.03442, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(85.86369, dtype=float32), 'eval/episode_swing_peak_std': Array(0.20863482, dtype=float32), 'eval/avg_episode_length': Array(94.15625, dtype=float32), 'eval/epoch_eval_time': 9.94900918006897, 'eval/sps': 12865.602763381174}\n",
      "2025-01-30 17:55:01,219 - INFO - starting iteration 8 569.9275555610657\n",
      "2025-01-30 17:55:51,783 - INFO - {'eval/walltime': 162.27293491363525, 'training/sps': np.float64(549508.1602573749), 'training/walltime': 415.7477252483368, 'training/entropy_loss': Array(-0.03956031, dtype=float32), 'training/policy_loss': Array(-0.03576054, dtype=float32), 'training/total_loss': Array(-0.0743757, dtype=float32), 'training/v_loss': Array(0.00094516, dtype=float32), 'eval/episode_reward': Array(1.7421905, dtype=float32), 'eval/episode_reward/action_rate': Array(-8.154211, dtype=float32), 'eval/episode_reward/alive': Array(79.484375, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-116.68492, dtype=float32), 'eval/episode_reward/base_height': Array(-0.40043527, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.8199275, dtype=float32), 'eval/episode_reward/energy': Array(-0.06924029, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.3581251, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.3760536, dtype=float32), 'eval/episode_reward/feet_height': Array(0.35916203, dtype=float32), 'eval/episode_reward/feet_phase': Array(24.773685, dtype=float32), 'eval/episode_reward/feet_slip': Array(-15.990665, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-5.2477827, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-4.6174, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-16.237617, dtype=float32), 'eval/episode_reward/orientation': Array(-15.172548, dtype=float32), 'eval/episode_reward/pose': Array(-8.990245, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00641783, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(21.214378, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(23.941608, dtype=float32), 'eval/episode_swing_peak': Array(0.32830063, dtype=float32), 'eval/episode_reward_std': Array(3.8679192, dtype=float32), 'eval/episode_reward/action_rate_std': Array(11.436417, dtype=float32), 'eval/episode_reward/alive_std': Array(118.23064, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(21.714205, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.26834157, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(3.3999858, dtype=float32), 'eval/episode_reward/energy_std': Array(0.04716382, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.1852201, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.29211137, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.29731354, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(31.343071, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(7.224445, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(6.635861, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(5.8772287, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(4.7446156, dtype=float32), 'eval/episode_reward/orientation_std': Array(2.0257077, dtype=float32), 'eval/episode_reward/pose_std': Array(16.449165, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00876158, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(36.541313, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(51.669605, dtype=float32), 'eval/episode_swing_peak_std': Array(0.2428394, dtype=float32), 'eval/avg_episode_length': Array(79.484375, dtype=float32), 'eval/epoch_eval_time': 9.963033437728882, 'eval/sps': 12847.492764129292}\n",
      "2025-01-30 17:55:51,865 - INFO - starting iteration 9 620.5739984512329\n",
      "2025-01-30 17:56:42,421 - INFO - {'eval/walltime': 172.21501278877258, 'training/sps': np.float64(549028.4674335025), 'training/walltime': 456.30176305770874, 'training/entropy_loss': Array(-0.03740595, dtype=float32), 'training/policy_loss': Array(-0.03565639, dtype=float32), 'training/total_loss': Array(-0.07210287, dtype=float32), 'training/v_loss': Array(0.00095947, dtype=float32), 'eval/episode_reward': Array(1.9790677, dtype=float32), 'eval/episode_reward/action_rate': Array(-7.7245493, dtype=float32), 'eval/episode_reward/alive': Array(80.33594, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-118.61852, dtype=float32), 'eval/episode_reward/base_height': Array(-0.4012053, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.4691129, dtype=float32), 'eval/episode_reward/energy': Array(-0.06852683, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.3175001, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.35850823, dtype=float32), 'eval/episode_reward/feet_height': Array(0.364033, dtype=float32), 'eval/episode_reward/feet_phase': Array(24.687609, dtype=float32), 'eval/episode_reward/feet_slip': Array(-17.017336, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-4.2097945, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-4.7291937, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-16.816135, dtype=float32), 'eval/episode_reward/orientation': Array(-15.243435, dtype=float32), 'eval/episode_reward/pose': Array(-7.81756, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00643931, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(22.329779, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(32.15735, dtype=float32), 'eval/episode_swing_peak': Array(0.27479333, dtype=float32), 'eval/episode_reward_std': Array(3.4553668, dtype=float32), 'eval/episode_reward/action_rate_std': Array(8.336772, dtype=float32), 'eval/episode_reward/alive_std': Array(94.278114, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(19.330122, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.21125294, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(1.6718111, dtype=float32), 'eval/episode_reward/energy_std': Array(0.03574035, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.1431072, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.19943565, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.2630544, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(24.745033, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(6.380453, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(5.5482965, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(5.0484133, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(4.841702, dtype=float32), 'eval/episode_reward/orientation_std': Array(2.8841348, dtype=float32), 'eval/episode_reward/pose_std': Array(9.044845, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00690566, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(32.962406, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(59.31213, dtype=float32), 'eval/episode_swing_peak_std': Array(0.18606749, dtype=float32), 'eval/avg_episode_length': Array(80.33594, dtype=float32), 'eval/epoch_eval_time': 9.942077875137329, 'eval/sps': 12874.572258189231}\n",
      "2025-01-30 17:56:42,503 - INFO - starting iteration 10 671.2113320827484\n",
      "2025-01-30 17:57:33,026 - INFO - {'eval/walltime': 182.1371250152588, 'training/sps': np.float64(549309.3675463741), 'training/walltime': 496.84603118896484, 'training/entropy_loss': Array(-0.03628581, dtype=float32), 'training/policy_loss': Array(-0.03567569, dtype=float32), 'training/total_loss': Array(-0.07108823, dtype=float32), 'training/v_loss': Array(0.00087326, dtype=float32), 'eval/episode_reward': Array(1.3207895, dtype=float32), 'eval/episode_reward/action_rate': Array(-5.9397936, dtype=float32), 'eval/episode_reward/alive': Array(61.734375, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-116.73004, dtype=float32), 'eval/episode_reward/base_height': Array(-0.36598253, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.3455086, dtype=float32), 'eval/episode_reward/energy': Array(-0.06245451, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.2543752, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.32843608, dtype=float32), 'eval/episode_reward/feet_height': Array(0.34277588, dtype=float32), 'eval/episode_reward/feet_phase': Array(20.107697, dtype=float32), 'eval/episode_reward/feet_slip': Array(-15.8401375, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-3.571094, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-4.5291667, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-16.594639, dtype=float32), 'eval/episode_reward/orientation': Array(-15.379021, dtype=float32), 'eval/episode_reward/pose': Array(-6.6166143, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00520462, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(18.479458, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(21.330355, dtype=float32), 'eval/episode_swing_peak': Array(0.30135638, dtype=float32), 'eval/episode_reward_std': Array(2.6962466, dtype=float32), 'eval/episode_reward/action_rate_std': Array(6.05539, dtype=float32), 'eval/episode_reward/alive_std': Array(74.21132, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(18.757442, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.17183672, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(1.1014658, dtype=float32), 'eval/episode_reward/energy_std': Array(0.02916965, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.1015414, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.16268578, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.2273384, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(19.783424, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(6.115568, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(4.3807926, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(4.950263, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(4.973905, dtype=float32), 'eval/episode_reward/orientation_std': Array(2.7163084, dtype=float32), 'eval/episode_reward/pose_std': Array(7.085934, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00578754, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(27.875536, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(41.71619, dtype=float32), 'eval/episode_swing_peak_std': Array(0.22280349, dtype=float32), 'eval/avg_episode_length': Array(61.734375, dtype=float32), 'eval/epoch_eval_time': 9.922112226486206, 'eval/sps': 12900.478958332607}\n",
      "2025-01-30 17:57:33,107 - INFO - starting iteration 11 721.8162295818329\n",
      "2025-01-30 17:58:23,571 - INFO - {'eval/walltime': 192.05957078933716, 'training/sps': np.float64(550395.3408979268), 'training/walltime': 537.3267962932587, 'training/entropy_loss': Array(-0.03510322, dtype=float32), 'training/policy_loss': Array(-0.03599583, dtype=float32), 'training/total_loss': Array(-0.07024339, dtype=float32), 'training/v_loss': Array(0.00085567, dtype=float32), 'eval/episode_reward': Array(1.6688712, dtype=float32), 'eval/episode_reward/action_rate': Array(-6.916876, dtype=float32), 'eval/episode_reward/alive': Array(73.24219, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-120.60602, dtype=float32), 'eval/episode_reward/base_height': Array(-0.39208376, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.5919361, dtype=float32), 'eval/episode_reward/energy': Array(-0.06519812, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.203125, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.35656103, dtype=float32), 'eval/episode_reward/feet_height': Array(0.335823, dtype=float32), 'eval/episode_reward/feet_phase': Array(23.198643, dtype=float32), 'eval/episode_reward/feet_slip': Array(-15.96189, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-4.2722044, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-4.4520893, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-16.897987, dtype=float32), 'eval/episode_reward/orientation': Array(-15.065537, dtype=float32), 'eval/episode_reward/pose': Array(-8.249996, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00581893, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(21.384699, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(24.541565, dtype=float32), 'eval/episode_swing_peak': Array(0.31975466, dtype=float32), 'eval/episode_reward_std': Array(3.1667454, dtype=float32), 'eval/episode_reward/action_rate_std': Array(7.6313415, dtype=float32), 'eval/episode_reward/alive_std': Array(91.00212, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(18.52703, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.2112956, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(2.1728544, dtype=float32), 'eval/episode_reward/energy_std': Array(0.0320876, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.0878146, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.20199849, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.27574748, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(24.051342, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(6.565652, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(5.641485, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(5.546306, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(4.4494214, dtype=float32), 'eval/episode_reward/orientation_std': Array(2.107976, dtype=float32), 'eval/episode_reward/pose_std': Array(13.001455, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00650658, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(33.421837, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(49.161808, dtype=float32), 'eval/episode_swing_peak_std': Array(0.23198135, dtype=float32), 'eval/avg_episode_length': Array(73.24219, dtype=float32), 'eval/epoch_eval_time': 9.92244577407837, 'eval/sps': 12900.045302781116}\n",
      "2025-01-30 17:58:23,653 - INFO - starting iteration 12 772.3615458011627\n",
      "2025-01-30 17:59:14,203 - INFO - {'eval/walltime': 202.02634286880493, 'training/sps': np.float64(549867.6957915142), 'training/walltime': 577.854115486145, 'training/entropy_loss': Array(-0.03386189, dtype=float32), 'training/policy_loss': Array(-0.03591821, dtype=float32), 'training/total_loss': Array(-0.06892467, dtype=float32), 'training/v_loss': Array(0.00085544, dtype=float32), 'eval/episode_reward': Array(2.03174, dtype=float32), 'eval/episode_reward/action_rate': Array(-7.8167424, dtype=float32), 'eval/episode_reward/alive': Array(85.59375, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-115.09354, dtype=float32), 'eval/episode_reward/base_height': Array(-0.40772718, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.4733636, dtype=float32), 'eval/episode_reward/energy': Array(-0.0707631, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.1075001, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.37393105, dtype=float32), 'eval/episode_reward/feet_height': Array(0.3266055, dtype=float32), 'eval/episode_reward/feet_phase': Array(26.687618, dtype=float32), 'eval/episode_reward/feet_slip': Array(-15.881148, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-4.577298, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-5.245878, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-15.945479, dtype=float32), 'eval/episode_reward/orientation': Array(-15.599883, dtype=float32), 'eval/episode_reward/pose': Array(-8.511903, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00683579, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(24.484676, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(26.918785, dtype=float32), 'eval/episode_swing_peak': Array(0.35516217, dtype=float32), 'eval/episode_reward_std': Array(3.37305, dtype=float32), 'eval/episode_reward/action_rate_std': Array(8.302078, dtype=float32), 'eval/episode_reward/alive_std': Array(100.84784, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(18.461815, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.22852387, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(1.9123522, dtype=float32), 'eval/episode_reward/energy_std': Array(0.03545567, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.1882945, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.23057275, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.27185908, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(26.758451, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(6.543926, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(5.1705446, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(5.4418063, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(4.595978, dtype=float32), 'eval/episode_reward/orientation_std': Array(3.0892758, dtype=float32), 'eval/episode_reward/pose_std': Array(10.853836, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00723926, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(33.859634, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(46.251377, dtype=float32), 'eval/episode_swing_peak_std': Array(0.2478838, dtype=float32), 'eval/avg_episode_length': Array(85.59375, dtype=float32), 'eval/epoch_eval_time': 9.966772079467773, 'eval/sps': 12842.673533559444}\n",
      "2025-01-30 17:59:14,288 - INFO - starting iteration 13 822.996289730072\n",
      "2025-01-30 18:00:04,777 - INFO - {'eval/walltime': 211.96026849746704, 'training/sps': np.float64(550217.1094394115), 'training/walltime': 618.3482673168182, 'training/entropy_loss': Array(-0.03322664, dtype=float32), 'training/policy_loss': Array(-0.03589849, dtype=float32), 'training/total_loss': Array(-0.06419944, dtype=float32), 'training/v_loss': Array(0.00492569, dtype=float32), 'eval/episode_reward': Array(2.143182, dtype=float32), 'eval/episode_reward/action_rate': Array(-7.8418126, dtype=float32), 'eval/episode_reward/alive': Array(86.078125, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-117.32866, dtype=float32), 'eval/episode_reward/base_height': Array(-0.41771665, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.6167474, dtype=float32), 'eval/episode_reward/energy': Array(-0.06962478, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.3943751, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.3720767, dtype=float32), 'eval/episode_reward/feet_height': Array(0.37092978, dtype=float32), 'eval/episode_reward/feet_phase': Array(26.477642, dtype=float32), 'eval/episode_reward/feet_slip': Array(-16.805944, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-4.9115295, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-5.0135574, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-16.700619, dtype=float32), 'eval/episode_reward/orientation': Array(-15.176749, dtype=float32), 'eval/episode_reward/pose': Array(-8.115419, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.0067302, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(26.080423, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(30.528765, dtype=float32), 'eval/episode_swing_peak': Array(0.2971263, dtype=float32), 'eval/episode_reward_std': Array(4.2881455, dtype=float32), 'eval/episode_reward/action_rate_std': Array(9.949441, dtype=float32), 'eval/episode_reward/alive_std': Array(121.00733, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(16.751928, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.2683827, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(1.9494281, dtype=float32), 'eval/episode_reward/energy_std': Array(0.04146761, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.2103589, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.26853788, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.3039305, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(31.93959, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(6.926547, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(5.843626, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(4.7452507, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(4.570819, dtype=float32), 'eval/episode_reward/orientation_std': Array(2.3368137, dtype=float32), 'eval/episode_reward/pose_std': Array(9.462862, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00826539, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(42.07428, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(64.24509, dtype=float32), 'eval/episode_swing_peak_std': Array(0.20447604, dtype=float32), 'eval/avg_episode_length': Array(86.078125, dtype=float32), 'eval/epoch_eval_time': 9.93392562866211, 'eval/sps': 12885.137737561148}\n",
      "2025-01-30 18:00:04,861 - INFO - starting iteration 14 873.5699474811554\n",
      "2025-01-30 18:00:55,310 - INFO - {'eval/walltime': 221.89856338500977, 'training/sps': np.float64(551038.2744367111), 'training/walltime': 658.8018996715546, 'training/entropy_loss': Array(-0.03295446, dtype=float32), 'training/policy_loss': Array(-0.0362263, dtype=float32), 'training/total_loss': Array(-0.06833211, dtype=float32), 'training/v_loss': Array(0.00084865, dtype=float32), 'eval/episode_reward': Array(1.8351402, dtype=float32), 'eval/episode_reward/action_rate': Array(-7.6762514, dtype=float32), 'eval/episode_reward/alive': Array(82.10156, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-117.849075, dtype=float32), 'eval/episode_reward/base_height': Array(-0.41137344, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.5769427, dtype=float32), 'eval/episode_reward/energy': Array(-0.06855783, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.3706251, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.37809587, dtype=float32), 'eval/episode_reward/feet_height': Array(0.34220034, dtype=float32), 'eval/episode_reward/feet_phase': Array(25.69851, dtype=float32), 'eval/episode_reward/feet_slip': Array(-16.939796, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-5.068134, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-4.6057596, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-17.327513, dtype=float32), 'eval/episode_reward/orientation': Array(-15.11647, dtype=float32), 'eval/episode_reward/pose': Array(-8.602715, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00652559, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(25.598217, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(20.216354, dtype=float32), 'eval/episode_swing_peak': Array(0.28882596, dtype=float32), 'eval/episode_reward_std': Array(3.5515673, dtype=float32), 'eval/episode_reward/action_rate_std': Array(9.728265, dtype=float32), 'eval/episode_reward/alive_std': Array(113.679016, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(18.662834, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.24061738, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(1.6415712, dtype=float32), 'eval/episode_reward/energy_std': Array(0.04218288, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.1795073, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.25546372, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.2548673, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(29.952662, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(6.0351605, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(6.509461, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(4.716858, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(4.215895, dtype=float32), 'eval/episode_reward/orientation_std': Array(2.366074, dtype=float32), 'eval/episode_reward/pose_std': Array(9.573155, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.0076966, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(42.785114, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(34.771923, dtype=float32), 'eval/episode_swing_peak_std': Array(0.20191318, dtype=float32), 'eval/avg_episode_length': Array(82.10156, dtype=float32), 'eval/epoch_eval_time': 9.938294887542725, 'eval/sps': 12879.472932569463}\n",
      "2025-01-30 18:00:55,396 - INFO - starting iteration 15 924.1043348312378\n",
      "2025-01-30 18:01:45,925 - INFO - {'eval/walltime': 231.84779691696167, 'training/sps': np.float64(549702.2599537097), 'training/walltime': 699.321347951889, 'training/entropy_loss': Array(-0.03276619, dtype=float32), 'training/policy_loss': Array(-0.03635033, dtype=float32), 'training/total_loss': Array(-0.06801737, dtype=float32), 'training/v_loss': Array(0.00109915, dtype=float32), 'eval/episode_reward': Array(1.6721988, dtype=float32), 'eval/episode_reward/action_rate': Array(-6.415509, dtype=float32), 'eval/episode_reward/alive': Array(70.03125, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-117.30317, dtype=float32), 'eval/episode_reward/base_height': Array(-0.37657803, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.3651803, dtype=float32), 'eval/episode_reward/energy': Array(-0.06264459, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.1593752, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.35331216, dtype=float32), 'eval/episode_reward/feet_height': Array(0.33904558, dtype=float32), 'eval/episode_reward/feet_phase': Array(22.151314, dtype=float32), 'eval/episode_reward/feet_slip': Array(-16.119139, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-3.365224, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-3.8598514, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-16.615767, dtype=float32), 'eval/episode_reward/orientation': Array(-15.1270685, dtype=float32), 'eval/episode_reward/pose': Array(-6.3359995, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.0054812, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(21.43462, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(24.934608, dtype=float32), 'eval/episode_swing_peak': Array(0.30565935, dtype=float32), 'eval/episode_reward_std': Array(3.197534, dtype=float32), 'eval/episode_reward/action_rate_std': Array(6.466282, dtype=float32), 'eval/episode_reward/alive_std': Array(82.884605, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(16.859116, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.18175821, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(1.2597091, dtype=float32), 'eval/episode_reward/energy_std': Array(0.0284516, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.055604, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.22809981, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.2610114, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(21.974073, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(6.7504764, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(4.004053, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(3.4097273, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(4.5713983, dtype=float32), 'eval/episode_reward/orientation_std': Array(2.2668676, dtype=float32), 'eval/episode_reward/pose_std': Array(5.02811, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00544448, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(31.704426, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(50.24037, dtype=float32), 'eval/episode_swing_peak_std': Array(0.22533663, dtype=float32), 'eval/avg_episode_length': Array(70.03125, dtype=float32), 'eval/epoch_eval_time': 9.949233531951904, 'eval/sps': 12865.312648349118}\n",
      "2025-01-30 18:01:46,010 - INFO - starting iteration 16 974.718385219574\n",
      "2025-01-30 18:02:36,509 - INFO - {'eval/walltime': 241.7966799736023, 'training/sps': np.float64(550065.5460899642), 'training/walltime': 739.8145086765289, 'training/entropy_loss': Array(-0.03158143, dtype=float32), 'training/policy_loss': Array(-0.03591402, dtype=float32), 'training/total_loss': Array(-0.06665865, dtype=float32), 'training/v_loss': Array(0.00083679, dtype=float32), 'eval/episode_reward': Array(2.35637, dtype=float32), 'eval/episode_reward/action_rate': Array(-7.7807007, dtype=float32), 'eval/episode_reward/alive': Array(89.57031, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-116.01361, dtype=float32), 'eval/episode_reward/base_height': Array(-0.41906464, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.4084764, dtype=float32), 'eval/episode_reward/energy': Array(-0.07029356, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.1206251, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.36760455, dtype=float32), 'eval/episode_reward/feet_height': Array(0.32233024, dtype=float32), 'eval/episode_reward/feet_phase': Array(27.471409, dtype=float32), 'eval/episode_reward/feet_slip': Array(-16.55855, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-5.0689554, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-5.62125, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-16.042446, dtype=float32), 'eval/episode_reward/orientation': Array(-15.467325, dtype=float32), 'eval/episode_reward/pose': Array(-7.9459696, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00703963, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(29.003422, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(33.795464, dtype=float32), 'eval/episode_swing_peak': Array(0.30346745, dtype=float32), 'eval/episode_reward_std': Array(5.1341414, dtype=float32), 'eval/episode_reward/action_rate_std': Array(8.735154, dtype=float32), 'eval/episode_reward/alive_std': Array(121.24096, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(22.27131, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.28219, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(1.5378691, dtype=float32), 'eval/episode_reward/energy_std': Array(0.03656993, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.1359797, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.23457074, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.24447805, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(32.053593, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(6.435977, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(6.4490576, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(6.031398, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(5.175452, dtype=float32), 'eval/episode_reward/orientation_std': Array(2.372348, dtype=float32), 'eval/episode_reward/pose_std': Array(8.13203, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00814783, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(51.85714, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(91.70934, dtype=float32), 'eval/episode_swing_peak_std': Array(0.24349855, dtype=float32), 'eval/avg_episode_length': Array(89.57031, dtype=float32), 'eval/epoch_eval_time': 9.948883056640625, 'eval/sps': 12865.76586248677}\n",
      "2025-01-30 18:02:36,596 - INFO - starting iteration 17 1025.3045718669891\n",
      "2025-01-30 18:03:27,094 - INFO - {'eval/walltime': 251.7475118637085, 'training/sps': np.float64(550810.7590543738), 'training/walltime': 780.3005275726318, 'training/entropy_loss': Array(-0.03120092, dtype=float32), 'training/policy_loss': Array(-0.03592644, dtype=float32), 'training/total_loss': Array(-0.06630502, dtype=float32), 'training/v_loss': Array(0.00082234, dtype=float32), 'eval/episode_reward': Array(2.2843885, dtype=float32), 'eval/episode_reward/action_rate': Array(-7.774641, dtype=float32), 'eval/episode_reward/alive': Array(89.94531, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-116.55176, dtype=float32), 'eval/episode_reward/base_height': Array(-0.41933453, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.3589635, dtype=float32), 'eval/episode_reward/energy': Array(-0.07028873, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.2637501, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.36906052, dtype=float32), 'eval/episode_reward/feet_height': Array(0.33431455, dtype=float32), 'eval/episode_reward/feet_phase': Array(27.503443, dtype=float32), 'eval/episode_reward/feet_slip': Array(-16.91422, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-4.8287606, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-5.2244525, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-16.375011, dtype=float32), 'eval/episode_reward/orientation': Array(-15.018871, dtype=float32), 'eval/episode_reward/pose': Array(-8.166647, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-1.984375, dtype=float32), 'eval/episode_reward/torques': Array(-0.00691192, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(26.081186, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(33.35592, dtype=float32), 'eval/episode_swing_peak': Array(0.2904126, dtype=float32), 'eval/episode_reward_std': Array(4.7164726, dtype=float32), 'eval/episode_reward/action_rate_std': Array(9.643384, dtype=float32), 'eval/episode_reward/alive_std': Array(129.13483, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(22.960371, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.27863413, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(1.5555024, dtype=float32), 'eval/episode_reward/energy_std': Array(0.04029366, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.2421498, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.2591515, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.30661088, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(33.83537, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(5.8958673, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(7.116995, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(5.607253, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(5.1314645, dtype=float32), 'eval/episode_reward/orientation_std': Array(2.107341, dtype=float32), 'eval/episode_reward/pose_std': Array(12.780964, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0.1760848, dtype=float32), 'eval/episode_reward/torques_std': Array(0.00849442, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(43.5194, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(66.10861, dtype=float32), 'eval/episode_swing_peak_std': Array(0.20762973, dtype=float32), 'eval/avg_episode_length': Array(89.94531, dtype=float32), 'eval/epoch_eval_time': 9.950831890106201, 'eval/sps': 12863.246150029563}\n",
      "2025-01-30 18:03:27,180 - INFO - starting iteration 18 1075.8884098529816\n",
      "2025-01-30 18:04:17,726 - INFO - {'eval/walltime': 261.69516110420227, 'training/sps': np.float64(549915.3087363092), 'training/walltime': 820.840738773346, 'training/entropy_loss': Array(-0.03044868, dtype=float32), 'training/policy_loss': Array(-0.03540721, dtype=float32), 'training/total_loss': Array(-0.06500947, dtype=float32), 'training/v_loss': Array(0.00084642, dtype=float32), 'eval/episode_reward': Array(1.9394443, dtype=float32), 'eval/episode_reward/action_rate': Array(-7.0065145, dtype=float32), 'eval/episode_reward/alive': Array(80.27344, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-118.97276, dtype=float32), 'eval/episode_reward/base_height': Array(-0.3979679, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.317863, dtype=float32), 'eval/episode_reward/energy': Array(-0.06646655, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.3487501, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.36036783, dtype=float32), 'eval/episode_reward/feet_height': Array(0.3570504, dtype=float32), 'eval/episode_reward/feet_phase': Array(24.832664, dtype=float32), 'eval/episode_reward/feet_slip': Array(-16.476898, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-4.598564, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-4.619639, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-16.693693, dtype=float32), 'eval/episode_reward/orientation': Array(-14.933214, dtype=float32), 'eval/episode_reward/pose': Array(-6.950178, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00618423, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(22.927628, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(26.935026, dtype=float32), 'eval/episode_swing_peak': Array(0.30276424, dtype=float32), 'eval/episode_reward_std': Array(4.4019256, dtype=float32), 'eval/episode_reward/action_rate_std': Array(8.942708, dtype=float32), 'eval/episode_reward/alive_std': Array(121.02038, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(18.407125, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.26200756, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(1.4264376, dtype=float32), 'eval/episode_reward/energy_std': Array(0.0396145, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.1152459, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.2542185, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.2599133, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(31.933887, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(7.0426397, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(6.1105638, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(4.9264545, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(4.874332, dtype=float32), 'eval/episode_reward/orientation_std': Array(2.0917525, dtype=float32), 'eval/episode_reward/pose_std': Array(6.3432407, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00800684, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(39.67261, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(64.09254, dtype=float32), 'eval/episode_swing_peak_std': Array(0.24187522, dtype=float32), 'eval/avg_episode_length': Array(80.27344, dtype=float32), 'eval/epoch_eval_time': 9.947649240493774, 'eval/sps': 12867.361615340433}\n",
      "2025-01-30 18:04:18,491 - INFO - total steps: 211681280\n",
      "2025-01-30 18:04:18,995 - INFO - Time to jit: 0:01:53.462314\n",
      "2025-01-30 18:04:18,996 - INFO - Time to train: 0:16:52.981138\n",
      "2025-01-30 18:04:19,042 - INFO - Model saved to: checkpoints/ZbotJoystickFlatTerrain_params.pkl\n",
      "2025-01-30 18:04:19,043 - INFO - Training completed. Final statistics:\n",
      "2025-01-30 18:04:19,043 - INFO -   Total steps: 20\n",
      "2025-01-30 18:04:19,043 - INFO -   Final reward: 1.94 ± 4.40\n",
      "2025-01-30 18:04:19,044 - INFO -   Training time: 1126.44s\n",
      "2025-01-30 18:04:19,044 - INFO - Saving training visualizations and metrics...\n",
      "2025-01-30 18:04:19,137 - INFO - Starting flat terrain policy evaluation...\n",
      "2025-01-30 18:04:19,457 - INFO - Episode 0\n",
      "2025-01-30 18:05:30,538 - INFO - fps: 50.0\n",
      "100%|██████████| 32/32 [00:05<00:00,  5.70it/s]\n",
      "2025-01-30 18:05:36,983 - INFO - Episode 1\n",
      "2025-01-30 18:05:37,463 - INFO - fps: 50.0\n",
      "100%|██████████| 32/32 [00:04<00:00,  6.69it/s]\n",
      "2025-01-30 18:05:43,007 - INFO - Episode 2\n",
      "2025-01-30 18:05:43,480 - INFO - fps: 50.0\n",
      "100%|██████████| 32/32 [00:04<00:00,  6.70it/s]\n",
      "2025-01-30 18:05:49,333 - INFO - ==================================================\n",
      "2025-01-30 18:05:49,333 - INFO - Starting rough terrain adaptation phase\n",
      "2025-01-30 18:05:49,335 - INFO - ==================================================\n",
      "2025-01-30 18:05:49,335 - INFO - Training configuration:\n",
      "2025-01-30 18:05:49,336 - INFO -   env: ZbotJoystickFlatTerrain\n",
      "2025-01-30 18:05:49,337 - INFO -   task: rough_terrain\n",
      "2025-01-30 18:05:49,339 - INFO -   debug: False\n",
      "2025-01-30 18:05:49,340 - INFO -   save_model: True\n",
      "2025-01-30 18:05:49,343 - INFO -   load_model: True\n",
      "2025-01-30 18:05:49,343 - INFO -   seed: 42\n",
      "2025-01-30 18:05:49,344 - INFO -   num_episodes: 3\n",
      "2025-01-30 18:05:49,345 - INFO -   episode_length: 3000\n",
      "2025-01-30 18:05:49,346 - INFO -   x_vel: 1.0\n",
      "2025-01-30 18:05:49,346 - INFO -   y_vel: 0.0\n",
      "2025-01-30 18:05:49,347 - INFO -   yaw_vel: 0.0\n",
      "2025-01-30 18:05:49,852 - INFO - RL config: action_repeat: 1\n",
      "batch_size: 512\n",
      "clipping_epsilon: 0.2\n",
      "discounting: 0.97\n",
      "entropy_cost: 0.01\n",
      "episode_length: 1000\n",
      "learning_rate: 0.0003\n",
      "max_grad_norm: 1.0\n",
      "network_factory:\n",
      "  policy_hidden_layer_sizes: &id001 !!python/tuple\n",
      "  - 1024\n",
      "  - 512\n",
      "  - 256\n",
      "  policy_obs_key: state\n",
      "  value_hidden_layer_sizes: *id001\n",
      "  value_obs_key: privileged_state\n",
      "normalize_observations: true\n",
      "num_envs: 16384\n",
      "num_evals: 20\n",
      "num_minibatches: 32\n",
      "num_resets_per_eval: 2\n",
      "num_timesteps: 200000000\n",
      "num_updates_per_batch: 8\n",
      "reward_scaling: 1.0\n",
      "unroll_length: 20\n",
      "\n",
      "2025-01-30 18:05:49,853 - INFO - Loading pre-trained flat terrain policy...\n",
      "2025-01-30 18:05:49,853 - INFO - Beginning rough terrain adaptation...\n",
      "2025-01-30 18:05:49,853 - INFO - Device count: 1, process count: 1 (id 0), local device count: 1, devices to be used count: 1\n",
      "2025-01-30 18:07:58,315 - INFO - {'eval/walltime': 84.43203401565552, 'eval/episode_reward': Array(0.2818298, dtype=float32), 'eval/episode_reward/action_rate': Array(-3.5530024, dtype=float32), 'eval/episode_reward/alive': Array(33.726562, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-120.50683, dtype=float32), 'eval/episode_reward/base_height': Array(-0.24723823, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.210266, dtype=float32), 'eval/episode_reward/energy': Array(-0.04382547, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.330625, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.24017929, dtype=float32), 'eval/episode_reward/feet_height': Array(0.23401678, dtype=float32), 'eval/episode_reward/feet_phase': Array(17.89231, dtype=float32), 'eval/episode_reward/feet_slip': Array(-14.300474, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-2.9594443, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-3.0714736, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-16.831688, dtype=float32), 'eval/episode_reward/orientation': Array(-15.138214, dtype=float32), 'eval/episode_reward/pose': Array(-4.6393385, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00257594, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(6.15486, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(7.0141416, dtype=float32), 'eval/episode_swing_peak': Array(0.5702439, dtype=float32), 'eval/episode_reward_std': Array(0.26597482, dtype=float32), 'eval/episode_reward/action_rate_std': Array(0.930804, dtype=float32), 'eval/episode_reward/alive_std': Array(8.271482, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(23.226416, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.04967576, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(0.9992572, dtype=float32), 'eval/episode_reward/energy_std': Array(0.01242133, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.1187882, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.04935756, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.16731139, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(4.3886375, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(5.4436827, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(1.8459712, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(1.6282165, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(4.0182905, dtype=float32), 'eval/episode_reward/orientation_std': Array(1.9573237, dtype=float32), 'eval/episode_reward/pose_std': Array(2.880251, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00068385, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(4.8354063, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(6.810388, dtype=float32), 'eval/episode_swing_peak_std': Array(0.4213813, dtype=float32), 'eval/avg_episode_length': Array(33.726562, dtype=float32), 'eval/epoch_eval_time': 84.43203401565552, 'eval/sps': 1516.0122753440482}\n",
      "2025-01-30 18:07:58,388 - INFO - starting iteration 0 128.53440022468567\n",
      "2025-01-30 18:10:46,326 - INFO - {'eval/walltime': 96.5557906627655, 'training/sps': np.float64(227748.19958666127), 'training/walltime': 155.47713470458984, 'training/entropy_loss': Array(-0.0637107, dtype=float32), 'training/policy_loss': Array(-0.01619354, dtype=float32), 'training/total_loss': Array(-0.06237311, dtype=float32), 'training/v_loss': Array(0.01753115, dtype=float32), 'eval/episode_reward': Array(0.2679451, dtype=float32), 'eval/episode_reward/action_rate': Array(-3.8316326, dtype=float32), 'eval/episode_reward/alive': Array(33.289062, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-117.9611, dtype=float32), 'eval/episode_reward/base_height': Array(-0.23932603, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.1127956, dtype=float32), 'eval/episode_reward/energy': Array(-0.04548448, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.3650001, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.23635578, dtype=float32), 'eval/episode_reward/feet_height': Array(0.2124477, dtype=float32), 'eval/episode_reward/feet_phase': Array(18.156422, dtype=float32), 'eval/episode_reward/feet_slip': Array(-13.898894, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-2.881946, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-2.849071, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-16.724989, dtype=float32), 'eval/episode_reward/orientation': Array(-15.141663, dtype=float32), 'eval/episode_reward/pose': Array(-4.398417, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00264495, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(5.74706, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(7.094184, dtype=float32), 'eval/episode_swing_peak': Array(0.5884422, dtype=float32), 'eval/episode_reward_std': Array(0.25762615, dtype=float32), 'eval/episode_reward/action_rate_std': Array(1.0153747, dtype=float32), 'eval/episode_reward/alive_std': Array(8.7724285, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(20.662996, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.04692764, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(0.9327085, dtype=float32), 'eval/episode_reward/energy_std': Array(0.01341658, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(0.8970926, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.0466566, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.12072469, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(4.8733325, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(5.1917605, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(1.8990178, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(1.3529052, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(4.295999, dtype=float32), 'eval/episode_reward/orientation_std': Array(2.3951273, dtype=float32), 'eval/episode_reward/pose_std': Array(3.5378532, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00074859, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(4.056564, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(7.3947453, dtype=float32), 'eval/episode_swing_peak_std': Array(0.40449092, dtype=float32), 'eval/avg_episode_length': Array(33.289062, dtype=float32), 'eval/epoch_eval_time': 12.123756647109985, 'eval/sps': 10557.78367429638}\n",
      "2025-01-30 18:10:46,415 - INFO - starting iteration 1 296.56146478652954\n",
      "2025-01-30 18:12:36,419 - INFO - {'eval/walltime': 108.62753438949585, 'training/sps': np.float64(227695.6190404836), 'training/walltime': 253.31481194496155, 'training/entropy_loss': Array(-0.06009725, dtype=float32), 'training/policy_loss': Array(-0.03739103, dtype=float32), 'training/total_loss': Array(-0.09691425, dtype=float32), 'training/v_loss': Array(0.00057403, dtype=float32), 'eval/episode_reward': Array(0.3113191, dtype=float32), 'eval/episode_reward/action_rate': Array(-3.8983605, dtype=float32), 'eval/episode_reward/alive': Array(33.367188, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-119.66174, dtype=float32), 'eval/episode_reward/base_height': Array(-0.2398557, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.0720956, dtype=float32), 'eval/episode_reward/energy': Array(-0.04494278, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.3500001, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.23760761, dtype=float32), 'eval/episode_reward/feet_height': Array(0.21797296, dtype=float32), 'eval/episode_reward/feet_phase': Array(18.353367, dtype=float32), 'eval/episode_reward/feet_slip': Array(-13.944214, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-2.6126714, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-2.6092286, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-17.138395, dtype=float32), 'eval/episode_reward/orientation': Array(-14.836239, dtype=float32), 'eval/episode_reward/pose': Array(-4.351842, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00267781, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(6.0010448, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(7.7575765, dtype=float32), 'eval/episode_swing_peak': Array(0.6359561, dtype=float32), 'eval/episode_reward_std': Array(0.4224214, dtype=float32), 'eval/episode_reward/action_rate_std': Array(1.3690248, dtype=float32), 'eval/episode_reward/alive_std': Array(12.135865, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(18.211681, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.04460035, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(0.8784133, dtype=float32), 'eval/episode_reward/energy_std': Array(0.01297195, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.0062307, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.05091567, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.12772013, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(6.7084465, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(4.7050343, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(1.7405262, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(1.5148469, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(3.8482077, dtype=float32), 'eval/episode_reward/orientation_std': Array(1.8936936, dtype=float32), 'eval/episode_reward/pose_std': Array(3.371488, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00097211, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(5.291586, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(8.967053, dtype=float32), 'eval/episode_swing_peak_std': Array(0.41785878, dtype=float32), 'eval/avg_episode_length': Array(33.367188, dtype=float32), 'eval/epoch_eval_time': 12.071743726730347, 'eval/sps': 10603.273470473932}\n",
      "2025-01-30 18:12:36,498 - INFO - starting iteration 2 406.64440655708313\n",
      "2025-01-30 18:14:26,582 - INFO - {'eval/walltime': 120.76151943206787, 'training/sps': np.float64(227796.91215818387), 'training/walltime': 351.16870951652527, 'training/entropy_loss': Array(-0.05660915, dtype=float32), 'training/policy_loss': Array(-0.03858408, dtype=float32), 'training/total_loss': Array(-0.09463079, dtype=float32), 'training/v_loss': Array(0.00056245, dtype=float32), 'eval/episode_reward': Array(0.38370723, dtype=float32), 'eval/episode_reward/action_rate': Array(-4.243533, dtype=float32), 'eval/episode_reward/alive': Array(35.953125, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-120.76693, dtype=float32), 'eval/episode_reward/base_height': Array(-0.24232705, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.2192259, dtype=float32), 'eval/episode_reward/energy': Array(-0.04877441, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.3275001, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.2452727, dtype=float32), 'eval/episode_reward/feet_height': Array(0.22577196, dtype=float32), 'eval/episode_reward/feet_phase': Array(19.239975, dtype=float32), 'eval/episode_reward/feet_slip': Array(-13.767348, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-2.9914126, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-2.931528, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-17.265476, dtype=float32), 'eval/episode_reward/orientation': Array(-14.618749, dtype=float32), 'eval/episode_reward/pose': Array(-4.453563, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.0029522, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(6.5240593, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(7.3195405, dtype=float32), 'eval/episode_swing_peak': Array(0.65076363, dtype=float32), 'eval/episode_reward_std': Array(0.64044446, dtype=float32), 'eval/episode_reward/action_rate_std': Array(2.219915, dtype=float32), 'eval/episode_reward/alive_std': Array(18.77867, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(18.425777, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.04711357, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(0.9886854, dtype=float32), 'eval/episode_reward/energy_std': Array(0.0158235, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.1883787, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.06891029, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.1760031, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(9.842037, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(5.8697414, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(1.8960825, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(1.700775, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(3.8823078, dtype=float32), 'eval/episode_reward/orientation_std': Array(1.7838603, dtype=float32), 'eval/episode_reward/pose_std': Array(4.178372, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.0014462, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(7.114822, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(10.861044, dtype=float32), 'eval/episode_swing_peak_std': Array(0.48350003, dtype=float32), 'eval/avg_episode_length': Array(35.953125, dtype=float32), 'eval/epoch_eval_time': 12.133985042572021, 'eval/sps': 10548.883944632591}\n",
      "2025-01-30 18:14:26,669 - INFO - starting iteration 3 516.8161911964417\n",
      "2025-01-30 18:16:16,661 - INFO - {'eval/walltime': 132.82628774642944, 'training/sps': np.float64(227617.03819987617), 'training/walltime': 448.99807024002075, 'training/entropy_loss': Array(-0.05316952, dtype=float32), 'training/policy_loss': Array(-0.04008813, dtype=float32), 'training/total_loss': Array(-0.09270183, dtype=float32), 'training/v_loss': Array(0.00055582, dtype=float32), 'eval/episode_reward': Array(0.4097595, dtype=float32), 'eval/episode_reward/action_rate': Array(-4.131456, dtype=float32), 'eval/episode_reward/alive': Array(35.328125, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-118.03076, dtype=float32), 'eval/episode_reward/base_height': Array(-0.2471635, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.1215416, dtype=float32), 'eval/episode_reward/energy': Array(-0.04668364, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.3350002, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.24413459, dtype=float32), 'eval/episode_reward/feet_height': Array(0.23775603, dtype=float32), 'eval/episode_reward/feet_phase': Array(18.867828, dtype=float32), 'eval/episode_reward/feet_slip': Array(-14.235351, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-2.6901817, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-2.4967246, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-17.446249, dtype=float32), 'eval/episode_reward/orientation': Array(-14.54232, dtype=float32), 'eval/episode_reward/pose': Array(-4.2891846, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00290314, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(7.288248, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(8.910202, dtype=float32), 'eval/episode_swing_peak': Array(0.6086028, dtype=float32), 'eval/episode_reward_std': Array(0.49639344, dtype=float32), 'eval/episode_reward/action_rate_std': Array(1.3656859, dtype=float32), 'eval/episode_reward/alive_std': Array(13.042664, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(16.774918, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.04460152, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(0.86932874, dtype=float32), 'eval/episode_reward/energy_std': Array(0.01190452, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.0648828, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.05833678, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.16199617, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(7.109946, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(5.1586995, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(2.112253, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(1.4022168, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(3.869677, dtype=float32), 'eval/episode_reward/orientation_std': Array(1.7896036, dtype=float32), 'eval/episode_reward/pose_std': Array(2.9366577, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.0010667, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(5.3409166, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(10.036509, dtype=float32), 'eval/episode_swing_peak_std': Array(0.44415405, dtype=float32), 'eval/avg_episode_length': Array(35.328125, dtype=float32), 'eval/epoch_eval_time': 12.064768314361572, 'eval/sps': 10609.403899421117}\n",
      "2025-01-30 18:16:16,746 - INFO - starting iteration 4 626.8926994800568\n",
      "2025-01-30 18:18:06,756 - INFO - {'eval/walltime': 144.91392421722412, 'training/sps': np.float64(227726.14611532798), 'training/walltime': 546.8201949596405, 'training/entropy_loss': Array(-0.04980875, dtype=float32), 'training/policy_loss': Array(-0.04044301, dtype=float32), 'training/total_loss': Array(-0.08968829, dtype=float32), 'training/v_loss': Array(0.00056347, dtype=float32), 'eval/episode_reward': Array(0.48980954, dtype=float32), 'eval/episode_reward/action_rate': Array(-4.26609, dtype=float32), 'eval/episode_reward/alive': Array(38.132812, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-119.04024, dtype=float32), 'eval/episode_reward/base_height': Array(-0.25049582, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.2329886, dtype=float32), 'eval/episode_reward/energy': Array(-0.05016014, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.2687502, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.25492764, dtype=float32), 'eval/episode_reward/feet_height': Array(0.22202165, dtype=float32), 'eval/episode_reward/feet_phase': Array(20.20417, dtype=float32), 'eval/episode_reward/feet_slip': Array(-14.816866, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-2.7536867, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-3.0014486, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-17.2621, dtype=float32), 'eval/episode_reward/orientation': Array(-14.929535, dtype=float32), 'eval/episode_reward/pose': Array(-4.067402, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00316554, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(6.8566365, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(10.352467, dtype=float32), 'eval/episode_swing_peak': Array(0.6180688, dtype=float32), 'eval/episode_reward_std': Array(0.7746018, dtype=float32), 'eval/episode_reward/action_rate_std': Array(2.1249413, dtype=float32), 'eval/episode_reward/alive_std': Array(21.984144, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(18.079971, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.05270301, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(0.9879128, dtype=float32), 'eval/episode_reward/energy_std': Array(0.0156401, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.0520331, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.07347037, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.16650279, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(10.464297, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(6.2081604, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(2.3727531, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(1.9324036, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(3.8842733, dtype=float32), 'eval/episode_reward/orientation_std': Array(2.4044323, dtype=float32), 'eval/episode_reward/pose_std': Array(2.587592, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00169134, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(6.3326426, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(14.30309, dtype=float32), 'eval/episode_swing_peak_std': Array(0.448977, dtype=float32), 'eval/avg_episode_length': Array(38.132812, dtype=float32), 'eval/epoch_eval_time': 12.087636470794678, 'eval/sps': 10589.332357013289}\n",
      "2025-01-30 18:18:06,848 - INFO - starting iteration 5 736.9943084716797\n",
      "2025-01-30 18:19:56,906 - INFO - {'eval/walltime': 156.98475193977356, 'training/sps': np.float64(227631.55445097934), 'training/walltime': 644.708756685257, 'training/entropy_loss': Array(-0.04822621, dtype=float32), 'training/policy_loss': Array(-0.04167688, dtype=float32), 'training/total_loss': Array(-0.0893199, dtype=float32), 'training/v_loss': Array(0.00058318, dtype=float32), 'eval/episode_reward': Array(0.4747677, dtype=float32), 'eval/episode_reward/action_rate': Array(-4.2267466, dtype=float32), 'eval/episode_reward/alive': Array(37.445312, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-120.60454, dtype=float32), 'eval/episode_reward/base_height': Array(-0.2521774, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.0465689, dtype=float32), 'eval/episode_reward/energy': Array(-0.04922452, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.4331251, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.25435758, dtype=float32), 'eval/episode_reward/feet_height': Array(0.22425929, dtype=float32), 'eval/episode_reward/feet_phase': Array(20.03133, dtype=float32), 'eval/episode_reward/feet_slip': Array(-14.175758, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-3.2050948, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-2.7995634, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-18.256117, dtype=float32), 'eval/episode_reward/orientation': Array(-14.155708, dtype=float32), 'eval/episode_reward/pose': Array(-4.397862, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00306781, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(8.361821, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(8.601995, dtype=float32), 'eval/episode_swing_peak': Array(0.6392635, dtype=float32), 'eval/episode_reward_std': Array(1.258907, dtype=float32), 'eval/episode_reward/action_rate_std': Array(4.4782314, dtype=float32), 'eval/episode_reward/alive_std': Array(40.309315, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(13.475071, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.06609565, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(0.8133887, dtype=float32), 'eval/episode_reward/energy_std': Array(0.02381319, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.216636, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.1137187, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.1785597, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(19.172663, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(6.294498, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(5.136414, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(2.0343862, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(3.7511084, dtype=float32), 'eval/episode_reward/orientation_std': Array(1.9112889, dtype=float32), 'eval/episode_reward/pose_std': Array(5.357722, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00296251, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(17.49092, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(9.324349, dtype=float32), 'eval/episode_swing_peak_std': Array(0.47578725, dtype=float32), 'eval/avg_episode_length': Array(37.445312, dtype=float32), 'eval/epoch_eval_time': 12.070827722549438, 'eval/sps': 10604.07810815525}\n",
      "2025-01-30 18:19:56,989 - INFO - starting iteration 6 847.1354167461395\n",
      "2025-01-30 18:21:46,992 - INFO - {'eval/walltime': 169.0508086681366, 'training/sps': np.float64(227917.257393385), 'training/walltime': 742.5470108985901, 'training/entropy_loss': Array(-0.04688967, dtype=float32), 'training/policy_loss': Array(-0.04235543, dtype=float32), 'training/total_loss': Array(-0.08865594, dtype=float32), 'training/v_loss': Array(0.00058915, dtype=float32), 'eval/episode_reward': Array(0.40331513, dtype=float32), 'eval/episode_reward/action_rate': Array(-4.030024, dtype=float32), 'eval/episode_reward/alive': Array(36.46875, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-119.27994, dtype=float32), 'eval/episode_reward/base_height': Array(-0.25709662, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.2671431, dtype=float32), 'eval/episode_reward/energy': Array(-0.04859201, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.5487502, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.25720084, dtype=float32), 'eval/episode_reward/feet_height': Array(0.23970889, dtype=float32), 'eval/episode_reward/feet_phase': Array(19.703194, dtype=float32), 'eval/episode_reward/feet_slip': Array(-14.210436, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-3.2923105, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-2.8401213, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-18.398193, dtype=float32), 'eval/episode_reward/orientation': Array(-14.5255165, dtype=float32), 'eval/episode_reward/pose': Array(-4.200062, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00304103, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(7.035392, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(7.723821, dtype=float32), 'eval/episode_swing_peak': Array(0.6231431, dtype=float32), 'eval/episode_reward_std': Array(0.367352, dtype=float32), 'eval/episode_reward/action_rate_std': Array(1.2715206, dtype=float32), 'eval/episode_reward/alive_std': Array(12.186017, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(14.963088, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.04181271, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(0.94715697, dtype=float32), 'eval/episode_reward/energy_std': Array(0.01417363, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.254023, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.05083044, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.16789141, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(6.534496, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(5.6370077, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(2.2532039, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(1.6968486, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(3.6229334, dtype=float32), 'eval/episode_reward/orientation_std': Array(2.0912495, dtype=float32), 'eval/episode_reward/pose_std': Array(3.1343904, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00108882, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(5.229657, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(8.006834, dtype=float32), 'eval/episode_swing_peak_std': Array(0.43103772, dtype=float32), 'eval/avg_episode_length': Array(36.46875, dtype=float32), 'eval/epoch_eval_time': 12.066056728363037, 'eval/sps': 10608.271026864742}\n",
      "2025-01-30 18:21:47,074 - INFO - starting iteration 7 957.221174955368\n",
      "2025-01-30 18:23:36,985 - INFO - {'eval/walltime': 181.10331654548645, 'training/sps': np.float64(228031.25676641118), 'training/walltime': 840.3053877353668, 'training/entropy_loss': Array(-0.04591569, dtype=float32), 'training/policy_loss': Array(-0.04314947, dtype=float32), 'training/total_loss': Array(-0.08847641, dtype=float32), 'training/v_loss': Array(0.00058874, dtype=float32), 'eval/episode_reward': Array(0.5810238, dtype=float32), 'eval/episode_reward/action_rate': Array(-4.2753944, dtype=float32), 'eval/episode_reward/alive': Array(38.976562, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-120.94133, dtype=float32), 'eval/episode_reward/base_height': Array(-0.26018542, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.0832049, dtype=float32), 'eval/episode_reward/energy': Array(-0.05167417, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.3231251, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.25706246, dtype=float32), 'eval/episode_reward/feet_height': Array(0.24822783, dtype=float32), 'eval/episode_reward/feet_phase': Array(20.370665, dtype=float32), 'eval/episode_reward/feet_slip': Array(-13.646659, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-2.8250957, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-3.0453835, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-18.07758, dtype=float32), 'eval/episode_reward/orientation': Array(-14.672135, dtype=float32), 'eval/episode_reward/pose': Array(-4.4633594, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00327972, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(8.941122, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(11.61713, dtype=float32), 'eval/episode_swing_peak': Array(0.67833525, dtype=float32), 'eval/episode_reward_std': Array(0.745869, dtype=float32), 'eval/episode_reward/action_rate_std': Array(1.9961565, dtype=float32), 'eval/episode_reward/alive_std': Array(19.069143, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(21.95259, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.05177584, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(1.0740921, dtype=float32), 'eval/episode_reward/energy_std': Array(0.01544198, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.1774508, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.06487992, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.1633629, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(8.963801, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(5.421485, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(1.9700633, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(1.9524345, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(4.1680017, dtype=float32), 'eval/episode_reward/orientation_std': Array(1.9980544, dtype=float32), 'eval/episode_reward/pose_std': Array(2.8617702, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00162909, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(8.057608, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(14.010382, dtype=float32), 'eval/episode_swing_peak_std': Array(0.4772726, dtype=float32), 'eval/avg_episode_length': Array(38.976562, dtype=float32), 'eval/epoch_eval_time': 12.052507877349854, 'eval/sps': 10620.196336112669}\n",
      "2025-01-30 18:23:37,072 - INFO - starting iteration 8 1067.219257593155\n",
      "2025-01-30 18:25:26,981 - INFO - {'eval/walltime': 193.1523962020874, 'training/sps': np.float64(227908.13449760817), 'training/walltime': 938.0658016204834, 'training/entropy_loss': Array(-0.04527554, dtype=float32), 'training/policy_loss': Array(-0.04346796, dtype=float32), 'training/total_loss': Array(-0.0881545, dtype=float32), 'training/v_loss': Array(0.000589, dtype=float32), 'eval/episode_reward': Array(0.42711163, dtype=float32), 'eval/episode_reward/action_rate': Array(-4.161187, dtype=float32), 'eval/episode_reward/alive': Array(36.859375, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-122.086754, dtype=float32), 'eval/episode_reward/base_height': Array(-0.25332713, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.1354063, dtype=float32), 'eval/episode_reward/energy': Array(-0.05138075, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.3100002, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.25341594, dtype=float32), 'eval/episode_reward/feet_height': Array(0.19609123, dtype=float32), 'eval/episode_reward/feet_phase': Array(20.465897, dtype=float32), 'eval/episode_reward/feet_slip': Array(-13.349689, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-3.3516855, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-2.6521964, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-18.46786, dtype=float32), 'eval/episode_reward/orientation': Array(-14.342177, dtype=float32), 'eval/episode_reward/pose': Array(-4.544441, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00306343, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(6.7790127, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(7.2106113, dtype=float32), 'eval/episode_swing_peak': Array(0.7143076, dtype=float32), 'eval/episode_reward_std': Array(0.79831046, dtype=float32), 'eval/episode_reward/action_rate_std': Array(3.2037358, dtype=float32), 'eval/episode_reward/alive_std': Array(27.094376, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(18.610323, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.05202399, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(0.8369353, dtype=float32), 'eval/episode_reward/energy_std': Array(0.01979961, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.0573553, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.0790389, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.13858098, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(13.67305, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(5.6987677, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(2.8984036, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(1.5410503, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(3.7942586, dtype=float32), 'eval/episode_reward/orientation_std': Array(1.7685779, dtype=float32), 'eval/episode_reward/pose_std': Array(3.1520016, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00203277, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(7.25403, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(7.476769, dtype=float32), 'eval/episode_swing_peak_std': Array(0.4591491, dtype=float32), 'eval/avg_episode_length': Array(36.859375, dtype=float32), 'eval/epoch_eval_time': 12.049079656600952, 'eval/sps': 10623.218009010061}\n",
      "2025-01-30 18:25:27,064 - INFO - starting iteration 9 1177.2112865447998\n",
      "2025-01-30 18:27:17,043 - INFO - {'eval/walltime': 205.27477836608887, 'training/sps': np.float64(227932.1188171553), 'training/walltime': 1035.8216083049774, 'training/entropy_loss': Array(-0.04504968, dtype=float32), 'training/policy_loss': Array(-0.044063, dtype=float32), 'training/total_loss': Array(-0.08850361, dtype=float32), 'training/v_loss': Array(0.00060907, dtype=float32), 'eval/episode_reward': Array(0.6101117, dtype=float32), 'eval/episode_reward/action_rate': Array(-4.4085665, dtype=float32), 'eval/episode_reward/alive': Array(39.5625, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-122.68004, dtype=float32), 'eval/episode_reward/base_height': Array(-0.25868455, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.2053676, dtype=float32), 'eval/episode_reward/energy': Array(-0.05311636, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.574375, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.2652213, dtype=float32), 'eval/episode_reward/feet_height': Array(0.28967738, dtype=float32), 'eval/episode_reward/feet_phase': Array(20.838518, dtype=float32), 'eval/episode_reward/feet_slip': Array(-13.881775, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-2.7731328, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-2.9001324, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-18.243032, dtype=float32), 'eval/episode_reward/orientation': Array(-14.300386, dtype=float32), 'eval/episode_reward/pose': Array(-4.1569586, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.0033032, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(8.466778, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(13.078662, dtype=float32), 'eval/episode_swing_peak': Array(0.67672276, dtype=float32), 'eval/episode_reward_std': Array(1.282298, dtype=float32), 'eval/episode_reward/action_rate_std': Array(4.082269, dtype=float32), 'eval/episode_reward/alive_std': Array(33.419388, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(19.593124, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.06079059, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(1.0240784, dtype=float32), 'eval/episode_reward/energy_std': Array(0.02410207, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(2.2040398, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.10278298, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.43593118, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(15.783476, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(5.611036, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(2.7116082, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(1.7507198, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(3.9828215, dtype=float32), 'eval/episode_reward/orientation_std': Array(1.7390456, dtype=float32), 'eval/episode_reward/pose_std': Array(3.005228, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00254192, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(7.781136, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(22.786194, dtype=float32), 'eval/episode_swing_peak_std': Array(0.54266906, dtype=float32), 'eval/avg_episode_length': Array(39.5625, dtype=float32), 'eval/epoch_eval_time': 12.122382164001465, 'eval/sps': 10558.980757107942}\n",
      "2025-01-30 18:27:17,131 - INFO - starting iteration 10 1287.2780838012695\n",
      "2025-01-30 18:29:07,077 - INFO - {'eval/walltime': 217.39122438430786, 'training/sps': np.float64(227991.5594260634), 'training/walltime': 1133.5522747039795, 'training/entropy_loss': Array(-0.04438948, dtype=float32), 'training/policy_loss': Array(-0.04391277, dtype=float32), 'training/total_loss': Array(-0.08769215, dtype=float32), 'training/v_loss': Array(0.0006101, dtype=float32), 'eval/episode_reward': Array(0.4061804, dtype=float32), 'eval/episode_reward/action_rate': Array(-3.9761286, dtype=float32), 'eval/episode_reward/alive': Array(35.382812, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-122.08998, dtype=float32), 'eval/episode_reward/base_height': Array(-0.2542897, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.1088066, dtype=float32), 'eval/episode_reward/energy': Array(-0.05124344, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.4100002, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.25308722, dtype=float32), 'eval/episode_reward/feet_height': Array(0.23130834, dtype=float32), 'eval/episode_reward/feet_phase': Array(19.290123, dtype=float32), 'eval/episode_reward/feet_slip': Array(-13.643039, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-2.8082557, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-2.873745, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-18.368877, dtype=float32), 'eval/episode_reward/orientation': Array(-14.244442, dtype=float32), 'eval/episode_reward/pose': Array(-4.4834223, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00300691, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(6.716255, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(8.304784, dtype=float32), 'eval/episode_swing_peak': Array(0.689772, dtype=float32), 'eval/episode_reward_std': Array(0.47633898, dtype=float32), 'eval/episode_reward/action_rate_std': Array(1.5938278, dtype=float32), 'eval/episode_reward/alive_std': Array(14.261026, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(13.950697, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.04327955, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(0.80223113, dtype=float32), 'eval/episode_reward/energy_std': Array(0.01613252, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.1630994, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.0664145, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.17532186, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(7.092964, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(5.4123826, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(2.2915163, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(1.5562031, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(3.2127454, dtype=float32), 'eval/episode_reward/orientation_std': Array(1.803296, dtype=float32), 'eval/episode_reward/pose_std': Array(3.3639665, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00118846, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(5.252408, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(9.122488, dtype=float32), 'eval/episode_swing_peak_std': Array(0.4945268, dtype=float32), 'eval/avg_episode_length': Array(35.382812, dtype=float32), 'eval/epoch_eval_time': 12.116446018218994, 'eval/sps': 10564.153862240772}\n",
      "2025-01-30 18:29:07,167 - INFO - starting iteration 11 1397.3137211799622\n",
      "2025-01-30 18:30:57,150 - INFO - {'eval/walltime': 229.506000995636, 'training/sps': np.float64(227788.89817668637), 'training/walltime': 1231.3219525814056, 'training/entropy_loss': Array(-0.04412084, dtype=float32), 'training/policy_loss': Array(-0.04431732, dtype=float32), 'training/total_loss': Array(-0.08783391, dtype=float32), 'training/v_loss': Array(0.00060425, dtype=float32), 'eval/episode_reward': Array(0.461611, dtype=float32), 'eval/episode_reward/action_rate': Array(-4.098671, dtype=float32), 'eval/episode_reward/alive': Array(36.828125, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-122.508995, dtype=float32), 'eval/episode_reward/base_height': Array(-0.25693828, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.1214719, dtype=float32), 'eval/episode_reward/energy': Array(-0.05119196, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.4781251, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.25813776, dtype=float32), 'eval/episode_reward/feet_height': Array(0.251163, dtype=float32), 'eval/episode_reward/feet_phase': Array(19.793186, dtype=float32), 'eval/episode_reward/feet_slip': Array(-13.914814, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-2.8582592, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-2.804389, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-18.096474, dtype=float32), 'eval/episode_reward/orientation': Array(-14.668755, dtype=float32), 'eval/episode_reward/pose': Array(-4.2836123, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00310879, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(7.060294, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(9.661986, dtype=float32), 'eval/episode_swing_peak': Array(0.65839887, dtype=float32), 'eval/episode_reward_std': Array(0.7148986, dtype=float32), 'eval/episode_reward/action_rate_std': Array(2.2735927, dtype=float32), 'eval/episode_reward/alive_std': Array(21.428337, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(19.784721, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.05295547, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(0.88820225, dtype=float32), 'eval/episode_reward/energy_std': Array(0.01750567, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.4106724, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.06914315, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.2505469, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(9.923502, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(5.859745, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(2.39425, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(1.754691, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(3.5488026, dtype=float32), 'eval/episode_reward/orientation_std': Array(2.5104558, dtype=float32), 'eval/episode_reward/pose_std': Array(2.8565707, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00183518, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(7.2033386, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(13.031335, dtype=float32), 'eval/episode_swing_peak_std': Array(0.45126823, dtype=float32), 'eval/avg_episode_length': Array(36.828125, dtype=float32), 'eval/epoch_eval_time': 12.114776611328125, 'eval/sps': 10565.609594510513}\n",
      "2025-01-30 18:30:57,239 - INFO - starting iteration 12 1507.3861484527588\n",
      "2025-01-30 18:32:47,143 - INFO - {'eval/walltime': 241.59750127792358, 'training/sps': np.float64(227952.21061185386), 'training/walltime': 1329.035751581192, 'training/entropy_loss': Array(-0.04396238, dtype=float32), 'training/policy_loss': Array(-0.0446757, dtype=float32), 'training/total_loss': Array(-0.088013, dtype=float32), 'training/v_loss': Array(0.00062508, dtype=float32), 'eval/episode_reward': Array(0.49440593, dtype=float32), 'eval/episode_reward/action_rate': Array(-4.225609, dtype=float32), 'eval/episode_reward/alive': Array(37.953125, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-120.818146, dtype=float32), 'eval/episode_reward/base_height': Array(-0.2545112, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.1164421, dtype=float32), 'eval/episode_reward/energy': Array(-0.05270823, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.3575001, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.26345706, dtype=float32), 'eval/episode_reward/feet_height': Array(0.24312538, dtype=float32), 'eval/episode_reward/feet_phase': Array(20.400621, dtype=float32), 'eval/episode_reward/feet_slip': Array(-12.952282, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-2.8116016, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-2.829211, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-17.983341, dtype=float32), 'eval/episode_reward/orientation': Array(-14.670657, dtype=float32), 'eval/episode_reward/pose': Array(-4.0858564, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00318158, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(7.2463913, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(9.101173, dtype=float32), 'eval/episode_swing_peak': Array(0.7890005, dtype=float32), 'eval/episode_reward_std': Array(0.8397723, dtype=float32), 'eval/episode_reward/action_rate_std': Array(2.6752963, dtype=float32), 'eval/episode_reward/alive_std': Array(23.783812, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(17.787746, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.059052, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(0.86632705, dtype=float32), 'eval/episode_reward/energy_std': Array(0.01817668, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.7327994, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.08028015, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.3559965, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(11.162128, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(6.06759, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(2.2308457, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(1.6267576, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(3.717655, dtype=float32), 'eval/episode_reward/orientation_std': Array(2.4621825, dtype=float32), 'eval/episode_reward/pose_std': Array(2.5594692, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00183397, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(6.6897287, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(14.21736, dtype=float32), 'eval/episode_swing_peak_std': Array(0.5890547, dtype=float32), 'eval/avg_episode_length': Array(37.953125, dtype=float32), 'eval/epoch_eval_time': 12.091500282287598, 'eval/sps': 10585.948559874127}\n",
      "2025-01-30 18:32:47,233 - INFO - starting iteration 13 1617.3800535202026\n",
      "2025-01-30 18:34:37,248 - INFO - {'eval/walltime': 253.6743471622467, 'training/sps': np.float64(227641.83514341316), 'training/walltime': 1426.876188993454, 'training/entropy_loss': Array(-0.04398585, dtype=float32), 'training/policy_loss': Array(-0.04415896, dtype=float32), 'training/total_loss': Array(-0.08747289, dtype=float32), 'training/v_loss': Array(0.00067191, dtype=float32), 'eval/episode_reward': Array(0.5119245, dtype=float32), 'eval/episode_reward/action_rate': Array(-4.1801653, dtype=float32), 'eval/episode_reward/alive': Array(37.398438, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-124.1436, dtype=float32), 'eval/episode_reward/base_height': Array(-0.2531651, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.1388918, dtype=float32), 'eval/episode_reward/energy': Array(-0.05253654, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.4318752, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.25107056, dtype=float32), 'eval/episode_reward/feet_height': Array(0.23317856, dtype=float32), 'eval/episode_reward/feet_phase': Array(20.086514, dtype=float32), 'eval/episode_reward/feet_slip': Array(-14.064488, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-3.0483508, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-3.0088592, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-18.099478, dtype=float32), 'eval/episode_reward/orientation': Array(-14.5710945, dtype=float32), 'eval/episode_reward/pose': Array(-4.678087, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00315175, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(7.529854, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(10.622019, dtype=float32), 'eval/episode_swing_peak': Array(0.6681309, dtype=float32), 'eval/episode_reward_std': Array(1.463036, dtype=float32), 'eval/episode_reward/action_rate_std': Array(3.2626333, dtype=float32), 'eval/episode_reward/alive_std': Array(27.768106, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(21.413633, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.05215471, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(0.87702334, dtype=float32), 'eval/episode_reward/energy_std': Array(0.02081951, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.1041214, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.07060999, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.15289181, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(14.747911, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(5.28053, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(2.0887358, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(1.67296, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(4.083555, dtype=float32), 'eval/episode_reward/orientation_std': Array(1.8034718, dtype=float32), 'eval/episode_reward/pose_std': Array(3.3729064, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00214765, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(13.109827, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(26.516272, dtype=float32), 'eval/episode_swing_peak_std': Array(0.45951578, dtype=float32), 'eval/avg_episode_length': Array(37.398438, dtype=float32), 'eval/epoch_eval_time': 12.07684588432312, 'eval/sps': 10598.793859426161}\n",
      "2025-01-30 18:34:37,340 - INFO - starting iteration 14 1727.4870200157166\n",
      "2025-01-30 18:36:27,253 - INFO - {'eval/walltime': 265.7534604072571, 'training/sps': np.float64(227971.47960156947), 'training/walltime': 1524.6124658584595, 'training/entropy_loss': Array(-0.04417334, dtype=float32), 'training/policy_loss': Array(-0.04485912, dtype=float32), 'training/total_loss': Array(-0.08837761, dtype=float32), 'training/v_loss': Array(0.00065486, dtype=float32), 'eval/episode_reward': Array(0.41939428, dtype=float32), 'eval/episode_reward/action_rate': Array(-3.9942784, dtype=float32), 'eval/episode_reward/alive': Array(35.84375, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-123.09757, dtype=float32), 'eval/episode_reward/base_height': Array(-0.25720733, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.1911074, dtype=float32), 'eval/episode_reward/energy': Array(-0.05052631, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.4318751, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.25522894, dtype=float32), 'eval/episode_reward/feet_height': Array(0.22330675, dtype=float32), 'eval/episode_reward/feet_phase': Array(19.474802, dtype=float32), 'eval/episode_reward/feet_slip': Array(-14.864648, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-3.1228528, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-2.6770132, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-18.594376, dtype=float32), 'eval/episode_reward/orientation': Array(-14.284075, dtype=float32), 'eval/episode_reward/pose': Array(-4.2286468, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00302039, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(7.427889, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(7.7387, dtype=float32), 'eval/episode_swing_peak': Array(0.59295297, dtype=float32), 'eval/episode_reward_std': Array(0.40515137, dtype=float32), 'eval/episode_reward/action_rate_std': Array(1.1653585, dtype=float32), 'eval/episode_reward/alive_std': Array(12.112389, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(19.541237, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.04466122, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(1.0043896, dtype=float32), 'eval/episode_reward/energy_std': Array(0.01533725, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.0890291, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.0458027, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.14654113, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(6.1352973, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(5.258881, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(1.8016927, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(1.3717275, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(3.576425, dtype=float32), 'eval/episode_reward/orientation_std': Array(2.0302596, dtype=float32), 'eval/episode_reward/pose_std': Array(2.9973135, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00109261, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(5.7159348, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(7.8650465, dtype=float32), 'eval/episode_swing_peak_std': Array(0.4331583, dtype=float32), 'eval/avg_episode_length': Array(35.84375, dtype=float32), 'eval/epoch_eval_time': 12.079113245010376, 'eval/sps': 10596.804368306926}\n",
      "2025-01-30 18:36:27,348 - INFO - starting iteration 15 1837.4944970607758\n",
      "2025-01-30 18:38:17,302 - INFO - {'eval/walltime': 277.8395302295685, 'training/sps': np.float64(227895.95473055766), 'training/walltime': 1622.3836591243744, 'training/entropy_loss': Array(-0.0440387, dtype=float32), 'training/policy_loss': Array(-0.04479636, dtype=float32), 'training/total_loss': Array(-0.08819168, dtype=float32), 'training/v_loss': Array(0.00064339, dtype=float32), 'eval/episode_reward': Array(0.4752642, dtype=float32), 'eval/episode_reward/action_rate': Array(-4.1674366, dtype=float32), 'eval/episode_reward/alive': Array(37.25, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-122.4503, dtype=float32), 'eval/episode_reward/base_height': Array(-0.2470953, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.16679, dtype=float32), 'eval/episode_reward/energy': Array(-0.05019181, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.0943751, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.2554235, dtype=float32), 'eval/episode_reward/feet_height': Array(0.19081894, dtype=float32), 'eval/episode_reward/feet_phase': Array(19.980833, dtype=float32), 'eval/episode_reward/feet_slip': Array(-13.617322, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-2.9348793, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-2.595891, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-17.924137, dtype=float32), 'eval/episode_reward/orientation': Array(-14.491701, dtype=float32), 'eval/episode_reward/pose': Array(-4.540074, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00309241, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(6.7494793, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(9.321789, dtype=float32), 'eval/episode_swing_peak': Array(0.7131026, dtype=float32), 'eval/episode_reward_std': Array(0.9130063, dtype=float32), 'eval/episode_reward/action_rate_std': Array(2.9610102, dtype=float32), 'eval/episode_reward/alive_std': Array(28.45089, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(19.61805, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.05870425, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(0.90517527, dtype=float32), 'eval/episode_reward/energy_std': Array(0.01696861, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(0.9885816, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.07441496, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.13534293, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(11.861369, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(6.6950674, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(3.54194, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(1.4776796, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(3.494789, dtype=float32), 'eval/episode_reward/orientation_std': Array(1.9531742, dtype=float32), 'eval/episode_reward/pose_std': Array(3.1224089, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00206638, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(6.8312516, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(13.435473, dtype=float32), 'eval/episode_swing_peak_std': Array(0.515806, dtype=float32), 'eval/avg_episode_length': Array(37.25, dtype=float32), 'eval/epoch_eval_time': 12.086069822311401, 'eval/sps': 10590.704991932656}\n",
      "2025-01-30 18:38:17,399 - INFO - starting iteration 16 1947.545645236969\n",
      "2025-01-30 18:40:07,385 - INFO - {'eval/walltime': 289.9220612049103, 'training/sps': np.float64(227869.96231785195), 'training/walltime': 1720.189207315445, 'training/entropy_loss': Array(-0.04406183, dtype=float32), 'training/policy_loss': Array(-0.0447509, dtype=float32), 'training/total_loss': Array(-0.08813288, dtype=float32), 'training/v_loss': Array(0.00067984, dtype=float32), 'eval/episode_reward': Array(0.5048749, dtype=float32), 'eval/episode_reward/action_rate': Array(-4.2417564, dtype=float32), 'eval/episode_reward/alive': Array(38.023438, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-125.61601, dtype=float32), 'eval/episode_reward/base_height': Array(-0.2602911, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.1519713, dtype=float32), 'eval/episode_reward/energy': Array(-0.052697, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.3106251, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.26209688, dtype=float32), 'eval/episode_reward/feet_height': Array(0.24455789, dtype=float32), 'eval/episode_reward/feet_phase': Array(20.297638, dtype=float32), 'eval/episode_reward/feet_slip': Array(-13.623449, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-3.0307627, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-2.9322333, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-18.348068, dtype=float32), 'eval/episode_reward/orientation': Array(-14.6182, dtype=float32), 'eval/episode_reward/pose': Array(-4.381571, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00319187, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(8.29693, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(9.189112, dtype=float32), 'eval/episode_swing_peak': Array(0.70519316, dtype=float32), 'eval/episode_reward_std': Array(1.0158064, dtype=float32), 'eval/episode_reward/action_rate_std': Array(3.0617502, dtype=float32), 'eval/episode_reward/alive_std': Array(27.668648, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(21.08966, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.05726299, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(1.050898, dtype=float32), 'eval/episode_reward/energy_std': Array(0.02396964, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.0975482, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.09424605, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.16675384, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(13.391248, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(5.8884077, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(3.0393229, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(1.6774278, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(3.9900856, dtype=float32), 'eval/episode_reward/orientation_std': Array(2.5108054, dtype=float32), 'eval/episode_reward/pose_std': Array(3.5007412, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.0020924, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(12.750812, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(11.926012, dtype=float32), 'eval/episode_swing_peak_std': Array(0.51349527, dtype=float32), 'eval/avg_episode_length': Array(38.023438, dtype=float32), 'eval/epoch_eval_time': 12.082530975341797, 'eval/sps': 10593.806898672492}\n",
      "2025-01-30 18:40:07,478 - INFO - starting iteration 17 2057.6249895095825\n",
      "2025-01-30 18:41:57,378 - INFO - {'eval/walltime': 302.0148811340332, 'training/sps': np.float64(228077.3130291099), 'training/walltime': 1817.8987953662872, 'training/entropy_loss': Array(-0.04410477, dtype=float32), 'training/policy_loss': Array(-0.04513961, dtype=float32), 'training/total_loss': Array(-0.08843368, dtype=float32), 'training/v_loss': Array(0.00081071, dtype=float32), 'eval/episode_reward': Array(0.53082526, dtype=float32), 'eval/episode_reward/action_rate': Array(-4.1604657, dtype=float32), 'eval/episode_reward/alive': Array(37.851562, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-122.24205, dtype=float32), 'eval/episode_reward/base_height': Array(-0.25356328, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-1.0717424, dtype=float32), 'eval/episode_reward/energy': Array(-0.0513671, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.2481251, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.25817132, dtype=float32), 'eval/episode_reward/feet_height': Array(0.21582697, dtype=float32), 'eval/episode_reward/feet_phase': Array(20.203247, dtype=float32), 'eval/episode_reward/feet_slip': Array(-14.119213, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-2.917789, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-3.022973, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-17.909918, dtype=float32), 'eval/episode_reward/orientation': Array(-14.5717125, dtype=float32), 'eval/episode_reward/pose': Array(-4.0975943, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00318939, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(7.779384, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(10.459608, dtype=float32), 'eval/episode_swing_peak': Array(0.67762494, dtype=float32), 'eval/episode_reward_std': Array(0.8945906, dtype=float32), 'eval/episode_reward/action_rate_std': Array(1.901397, dtype=float32), 'eval/episode_reward/alive_std': Array(19.719553, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(18.209852, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.05660781, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(0.778077, dtype=float32), 'eval/episode_reward/energy_std': Array(0.01526632, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.1110508, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.07762904, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.23649621, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(9.0886755, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(6.083773, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(1.8860426, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(1.9831884, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(3.8139625, dtype=float32), 'eval/episode_reward/orientation_std': Array(2.1374123, dtype=float32), 'eval/episode_reward/pose_std': Array(2.537065, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00165066, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(9.029091, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(16.900826, dtype=float32), 'eval/episode_swing_peak_std': Array(0.5607227, dtype=float32), 'eval/avg_episode_length': Array(37.851562, dtype=float32), 'eval/epoch_eval_time': 12.092819929122925, 'eval/sps': 10584.793352602552}\n",
      "2025-01-30 18:41:57,473 - INFO - starting iteration 18 2167.6202178001404\n",
      "2025-01-30 18:43:47,471 - INFO - {'eval/walltime': 314.1421642303467, 'training/sps': np.float64(227789.8897611205), 'training/walltime': 1915.6711015701294, 'training/entropy_loss': Array(-0.04371312, dtype=float32), 'training/policy_loss': Array(-0.04470596, dtype=float32), 'training/total_loss': Array(-0.08773779, dtype=float32), 'training/v_loss': Array(0.00068129, dtype=float32), 'eval/episode_reward': Array(0.6061686, dtype=float32), 'eval/episode_reward/action_rate': Array(-4.487174, dtype=float32), 'eval/episode_reward/alive': Array(40.34375, dtype=float32), 'eval/episode_reward/ang_vel_xy': Array(-124.38443, dtype=float32), 'eval/episode_reward/base_height': Array(-0.2534401, dtype=float32), 'eval/episode_reward/dof_pos_limits': Array(-0.9461485, dtype=float32), 'eval/episode_reward/energy': Array(-0.05438874, dtype=float32), 'eval/episode_reward/feet_air_time': Array(-1.3556252, dtype=float32), 'eval/episode_reward/feet_clearance': Array(0.25761944, dtype=float32), 'eval/episode_reward/feet_height': Array(0.23531424, dtype=float32), 'eval/episode_reward/feet_phase': Array(21.916275, dtype=float32), 'eval/episode_reward/feet_slip': Array(-13.895618, dtype=float32), 'eval/episode_reward/joint_deviation_hip': Array(-2.8059669, dtype=float32), 'eval/episode_reward/joint_deviation_knee': Array(-2.9334402, dtype=float32), 'eval/episode_reward/lin_vel_z': Array(-18.17207, dtype=float32), 'eval/episode_reward/orientation': Array(-14.504643, dtype=float32), 'eval/episode_reward/pose': Array(-4.439188, dtype=float32), 'eval/episode_reward/stand_still': Array(0., dtype=float32), 'eval/episode_reward/termination': Array(-2., dtype=float32), 'eval/episode_reward/torques': Array(-0.00336604, dtype=float32), 'eval/episode_reward/tracking_ang_vel': Array(7.7427254, dtype=float32), 'eval/episode_reward/tracking_lin_vel': Array(10.71793, dtype=float32), 'eval/episode_swing_peak': Array(0.6925065, dtype=float32), 'eval/episode_reward_std': Array(1.5226637, dtype=float32), 'eval/episode_reward/action_rate_std': Array(4.5991077, dtype=float32), 'eval/episode_reward/alive_std': Array(42.21882, dtype=float32), 'eval/episode_reward/ang_vel_xy_std': Array(17.814297, dtype=float32), 'eval/episode_reward/base_height_std': Array(0.06326319, dtype=float32), 'eval/episode_reward/dof_pos_limits_std': Array(0.8448258, dtype=float32), 'eval/episode_reward/energy_std': Array(0.0271214, dtype=float32), 'eval/episode_reward/feet_air_time_std': Array(1.1628116, dtype=float32), 'eval/episode_reward/feet_clearance_std': Array(0.094644, dtype=float32), 'eval/episode_reward/feet_height_std': Array(0.17638153, dtype=float32), 'eval/episode_reward/feet_phase_std': Array(21.114035, dtype=float32), 'eval/episode_reward/feet_slip_std': Array(6.442373, dtype=float32), 'eval/episode_reward/joint_deviation_hip_std': Array(2.3698888, dtype=float32), 'eval/episode_reward/joint_deviation_knee_std': Array(1.9812807, dtype=float32), 'eval/episode_reward/lin_vel_z_std': Array(3.4045174, dtype=float32), 'eval/episode_reward/orientation_std': Array(2.4651532, dtype=float32), 'eval/episode_reward/pose_std': Array(3.1145315, dtype=float32), 'eval/episode_reward/stand_still_std': Array(0., dtype=float32), 'eval/episode_reward/termination_std': Array(0., dtype=float32), 'eval/episode_reward/torques_std': Array(0.00311933, dtype=float32), 'eval/episode_reward/tracking_ang_vel_std': Array(11.156847, dtype=float32), 'eval/episode_reward/tracking_lin_vel_std': Array(20.320118, dtype=float32), 'eval/episode_swing_peak_std': Array(0.4603927, dtype=float32), 'eval/avg_episode_length': Array(40.34375, dtype=float32), 'eval/epoch_eval_time': 12.127283096313477, 'eval/sps': 10554.713614206812}\n",
      "2025-01-30 18:43:48,348 - INFO - total steps: 211681280\n",
      "2025-01-30 18:43:48,970 - INFO - Time to jit: 0:02:08.470406\n",
      "2025-01-30 18:43:48,970 - INFO - Time to train: 0:35:49.157361\n",
      "2025-01-30 18:43:49,024 - INFO - Model saved to: checkpoints/ZbotJoystickFlatTerrain_params.pkl\n",
      "2025-01-30 18:43:49,025 - INFO - Adaptation completed. Final statistics:\n",
      "2025-01-30 18:43:49,025 - INFO -   Total steps: 20\n",
      "2025-01-30 18:43:49,026 - INFO -   Final reward: 0.61 ± 1.52\n",
      "2025-01-30 18:43:49,026 - INFO -   Training time: 2277.63s\n",
      "2025-01-30 18:43:49,027 - INFO - Saving training visualizations and metrics...\n",
      "2025-01-30 18:43:49,122 - INFO - Starting rough terrain policy evaluation...\n",
      "2025-01-30 18:43:49,363 - INFO - Episode 0\n",
      "2025-01-30 18:45:15,390 - INFO - fps: 50.0\n",
      "100%|██████████| 28/28 [00:05<00:00,  5.53it/s]\n",
      "2025-01-30 18:45:21,250 - INFO - Episode 1\n",
      "2025-01-30 18:45:21,716 - INFO - fps: 50.0\n",
      "100%|██████████| 28/28 [00:04<00:00,  5.67it/s]\n",
      "2025-01-30 18:45:27,428 - INFO - Episode 2\n",
      "2025-01-30 18:45:27,879 - INFO - fps: 50.0\n",
      "100%|██████████| 28/28 [00:04<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 'function' object has no attribute 'display'\n",
      "No rendered video found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_10042/1297478277.py\", line 47, in <module>\n",
      "    display.display(plt.gcf())\n",
      "AttributeError: 'function' object has no attribute 'display'\n"
     ]
    }
   ],
   "source": [
    "#@title Run Training\n",
    "#@markdown Click to start training\n",
    "\n",
    "# First, ensure we're in the correct directory\n",
    "import os\n",
    "os.chdir('/home/jovyan/mujoco_playground')\n",
    "\n",
    "# Add the repository root to Python path\n",
    "import sys\n",
    "sys.path.insert(0, '/home/jovyan/mujoco_playground')\n",
    "\n",
    "# Add helper function for video display\n",
    "from IPython.display import HTML, display\n",
    "from base64 import b64encode\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_video(video_path):\n",
    "    \"\"\"Display a video in the notebook\"\"\"\n",
    "    mp4 = open(video_path,'rb').read()\n",
    "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "    return HTML(\"\"\"\n",
    "        <video width=600 controls>\n",
    "            <source src=\"%s\" type=\"video/mp4\">\n",
    "        </video>\n",
    "    \"\"\" % data_url)\n",
    "\n",
    "# Import after path setup\n",
    "from playground.zbot import zbot_constants\n",
    "from playground.runner import ZBotRunner\n",
    "from train_zbot import create_training_args, train_flat_terrain, train_rough_terrain, train_with_curriculum\n",
    "\n",
    "# Verify XML file exists\n",
    "xml_path = zbot_constants.task_to_xml(TASK)\n",
    "print(f\"Looking for XML file at: {xml_path}\")\n",
    "print(f\"File exists: {os.path.exists(xml_path)}\")\n",
    "\n",
    "# Run training with proper error handling\n",
    "try:\n",
    "    if TASK == \"flat_terrain\":\n",
    "        print(\"Starting flat terrain training...\")\n",
    "        runner = train_flat_terrain()\n",
    "    else:\n",
    "        print(\"Starting rough terrain training with curriculum...\")\n",
    "        flat_runner = train_flat_terrain()\n",
    "        if CURRICULUM_LEARNING:\n",
    "            runner = train_with_curriculum(flat_runner)\n",
    "        else:\n",
    "            runner = train_rough_terrain(flat_runner)\n",
    "\n",
    "    # Display training progress plot\n",
    "    plt.figure()\n",
    "    plt.plot(runner.x_data, runner.y_data, label='Mean Reward')\n",
    "    plt.fill_between(\n",
    "        runner.x_data,\n",
    "        np.array(runner.y_data) - np.array(runner.y_dataerr),\n",
    "        np.array(runner.y_data) + np.array(runner.y_dataerr),\n",
    "        alpha=0.2\n",
    "    )\n",
    "    plt.xlabel('Training Steps')\n",
    "    plt.ylabel('Episode Reward')\n",
    "    plt.title('Training Progress')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    display(plt.gcf())\n",
    "    plt.close()\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Could not find required files: {e}\")\n",
    "    print(\"Current working directory:\", os.getcwd())\n",
    "    print(\"\\nContents of zbot directory:\")\n",
    "    !ls -R playground/zbot/\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "# After training completes, display the video\n",
    "if os.path.exists(\"renders/episode_0.mp4\"):\n",
    "    display(show_video(\"renders/episode_0.mp4\"))\n",
    "else:\n",
    "    print(\"No rendered video found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6bhU3AmvZ0tq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
